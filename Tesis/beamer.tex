\documentclass{beamer}

%% Beamer stuff

\usepackage{color}
\usepackage{amsfonts}
\usepackage{ upgreek }
\usepackage[spanish, activeacute]{babel}
\usepackage{graphicx}
\usepackage{epsfig}
%   \usepackage{epstopdf}
%   \DeclareGraphicsRule{.eps}{pdf}{.pdf}{'epstopdf #1'}
%   \pdfcompresslevel=9
\usecolortheme[rgb={.2,.0,.7}]{structure}
\setbeamercolor{graybox}{bg=lightgray}
\colorlet{darkred}{red!65!black}
\colorlet{darkblue}{blue!65!black}
\colorlet{darkgreen}{green!50!black}
\colorlet{darkorange}{orange!85!black}
\definecolor{red1}{rgb}{0.8,0,0}
\definecolor{red2}{rgb}{0.7,0,0}
\definecolor{red3}{rgb}{0.6,0,0}
\definecolor{red4}{rgb}{0.5,0,0}

\definecolor{green1}{rgb}{0,0.8,0}
\definecolor{green2}{rgb}{0,0.7,0}
\definecolor{green3}{rgb}{0,0.6,0}
\definecolor{green4}{rgb}{0,0.5,0}

\definecolor{blue1}{rgb}{0,0,0.8}
\definecolor{blue2}{rgb}{0,0,0.7}
\definecolor{blue3}{rgb}{0,0,0.6}
\definecolor{blue4}{rgb}{0,0,0.4}

\definecolor{cyan1}{rgb}{0,0.8,0.8}
\definecolor{cyan2}{rgb}{0,0.7,0.7}
\definecolor{cyan3}{rgb}{0,0.6,0.6}
\definecolor{cyan4}{rgb}{0,0.5,0.5}

\definecolor{magenta1}{rgb}{0.8,0,0.8}
\definecolor{magenta2}{rgb}{0.7,0,0.7}
\definecolor{magenta3}{rgb}{0.6,0,0.6}
\definecolor{magenta4}{rgb}{0.5,0,0.5}

%\useoutertheme{infolines}
%\author{Rouben Rostamian}
%\title{Beamer tutorial}
%\institute{UMBC}

\mode<presentation> {
	%\usetheme{Hannover}
	\usetheme{CambridgeUS}
	%\usetheme{Singapore}
	%\usetheme{Madrid}
	%\usetheme{Marburg}
	% or ...
	
	\setbeamercovered{transparent}
	% or whatever (possibly just delete it)
}

%\useoutertheme{shadow}
\usecolortheme{seagull}
\setbeamertemplate{footline}{}

\beamertemplatenavigationsymbolsempty

%% Standard structure

\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[ruled,vlined,linesnumbered,resetcount]{algorithm2e}
\usepackage{amsfonts}
\usepackage{xr}
\usepackage{amsmath,amsfonts, amssymb, mathrsfs }
\usepackage{tikz-cd}
\usepackage{syntonly}
\usepackage{mathrsfs}
\usepackage{lmodern}
\usepackage{amsmath,amsbsy,amscd,amssymb,graphicx, epsfig,color}
%\usetheme{Boadilla}
%\usecolortheme{beaver}
%\setbeamercolor{block body alerted}{bg=normal text.bg!90!black}
%\setbeamercolor{block body}{bg=normal text.bg!90!black}
%\setbeamercolor{block body example}{bg=normal text.bg!90!black}
%\setbeamercolor{block title alerted}{use={normal text,alerted text},fg=alerted text.fg!75!normal text.fg,bg=normal text.bg!75!black}
%\setbeamercolor{block title}{bg=shadecolor, fg=black}
%\setbeamercolor{block title example}{use={normal text,example text},fg=example text.fg!75!normal text.fg,bg=normal text.bg!75!black}
%\setbeamercolor{item projected}{fg=black, bg=darkred}
%\definecolor{shadecolor}{rgb}{0.8,0.8,0.8}
%\definecolor{mapblue}{HTML}{3333B3}

\uselanguage{Spanish}
\languagepath{Spanish}

\def \ee{\varepsilon}
\def \a{\alpha}
\def \b{\beta}

\newtheorem{proposition}[theorem]{Proposici\'on}
\newtheorem{claim}[theorem]{Afirmaci\'on}
\newtheorem{hyp}[theorem]{Hip\'otesis}

\def \K{\hbox{Ker}}
\newcommand{\puntosfijos}{\mathcal{A}_{g}^{*}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\Cont}{\mathcal{C}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\inte}{\mathrm{int}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\inc}{\hookrightarrow}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\R}{{\mathbb{R}}}
\newcommand{\N}{{\mathbb{N}}}
\newcommand\tq{~:~}
\newcommand{\dual}[1]{\left(#1\right)^{\ast}}
\newcommand{\ortogonal}[1]{\left(#1\right)^{\perp}}
\newcommand{\ddual}[1]{\left(#1^{\ast}\right)^{\ast}}
\newcommand{\parenthesis}[1]{\left(#1\right)}
\newcommand{\x}[3]{#1_#2^#3}
\newcommand{\xx}[4]{#1_#3#2_#4}
\newcommand\dd{\,\mathrm{d}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\ip}[1]{\left\langle#1\right\rangle}
\renewcommand\tt{\mathbf{t}}
\newcommand\nn{\mathbf{n}}
\newcommand\bb{\mathbf{b}}                      % binormal
\newcommand\kk{\kappa}
\newcommand{\sett}[1]{\left\lbrace#1\right\rbrace}
\newcommand{\interior}[1]{\accentset{\smash{\raisebox{-0.12ex}{$\scriptstyle\circ$}}}{#1}\rule{0pt}{2.3ex}}
\fboxrule0.0001pt \fboxsep0pt
\newcommand{\Bigcup}[2]{\bigcup\limits_{#1}{#2}}
\newcommand{\Bigcap}[2]{\bigcap\limits_{#1}{#2}}
\newcommand{\Bigprod}[2]{\prod\limits_{#1}{#2}}
\newcommand{\Bigcoprod}[2]{\coprod\limits_{#1}{#2}}
\newcommand{\Bigsum}[2]{\sum\limits_{#1}{#2}}
\newcommand{\BigsumA}[3]{ \sideset{}{^#2}\sum\limits_{#1}{#3}}
\newcommand{\Biglim}[2]{\lim\limits_{#1}{#2}}
\newcommand{\quotient}[2]{{\raisebox{.2em}{$#1$}\left/\raisebox{-.2em}{$#2$}\right.}}
\newcommand{\expectation}[1]{\mathbb{E} \left[#1\right]}
\newcommand{\conditionalExpectation}[2]{\mathbb{E} \left[#1 \vert #2\right]}
\newcommand{\expectationsub}[2]{\mathbb{E}_{#1} \left[#2\right]}
\newcommand{\variancesub}[2]{\mathbb{V}_{#1} \left[#2\right]}
\newcommand{\expectationchik}[1]{\expectationsub{\upxi_{k}}{#1}}
\newcommand{\expectationfilt}[1]{\mathbb{E} \left[{#1} \vert \mathcal{P}_{k}\right]}
\newcommand{\variancechik}[1]{\variancesub{\upxi_{k}}{#1}}
\newcommand{\underlimitinf}[1]{\xrightarrow[#1 \rightarrow \infty]{}}
\newcommand{\mani}{\upchi}
\DeclareMathOperator{\rank}{ran}
\DeclareMathOperator{\graf}{Gr}
\DeclareMathOperator{\ball}{ball}

\def \le{\leqslant}	
\def \ge{\geqslant}
\def\noi{\noindent}
\def\sm{\smallskip}
\def\ms{\medskip}
\def\bs{\bigskip}
\def \be{\begin{enumerate}}
	\def \en{\end{enumerate}}
\def\deck{{\rm Deck}}
\def\Tau{{\rm T}}
\newcommand{\myTitle}{M\'etodos de primer orden\xspace}
\newcommand{\mySubtitle}{An\'alisis de convergencia\xspace}
\newcommand{\myDegree}{Tesis de Licenciatura\xspace}
\newcommand{\myName}{Axel Sirota\xspace}
\newcommand{\myDirector}{Director de Tesis: Dr. Pablo Amster\xspace}
\newcommand{\myFaculty}{Facultad de Ciencias Exactas y Naturales\xspace}
\newcommand{\myDepartment}{Departamento de Matem\'atica\xspace}
\newcommand{\myUni}{Universidad de Buenos Aires\xspace}
\newcommand{\myLocation}{Buenos Aires\xspace}
\newcommand{\myTime}{Noviembre 2018\xspace}
\newcommand{\myVersion}{version 2.0}

\title[]
%{Sistemas de ecuaciones polinomiales ralas}
{\textbf{\textcolor[rgb]{0.0,0.50,0}{\Large \myTitle: \mySubtitle}}}
\title[\myTitle: \mySubtitle]{\bf {\myTitle}}
\author[\myName]{\myName}
\institute{\myFaculty}
\date[\myTime]{\myDepartment}

\AtBeginSection[] {
\begin{frame}{Hoja de ruta}
\tableofcontents[currentsection]
\end{frame}
}

\begin{document}

\begin{frame}

\titlepage
\vspace{-1.6cm}
\begin{center}
	
\end{center}
\end{frame}

\section{Introducci\'on}

\begin{frame}{Marco te\'orico del problema}
Consideremos una muestra aleatoria $\sett{x_i, y_i}_{i \leq N} \subset \R^{d_x} \times \R^{d_y}$ tomada bajo una distribuci\'on $\mathbb{P}(x,y)$.

\bigskip

El objetivo del \textit{Machine Learning} es encontrar $h^* \in \mathcal{H} = \sett{h : \R^{d_x} \rightarrow \R^{d_y}}$ tal que $R(h) = \mathbb{E} \left[1 \left[h(x) \neq y \right] \right]$ sea m\'inima.

\bigskip
\pause

Dicho contexto es \textit{variacional} y \textit{estoc\'astico}. 

\pause
\bigskip

La pr\'actica usual consiste en tomar una dada $\widetilde{h}: \R^{d_x} \times \R^d \rightarrow \R^{d_y}$ que surge del conocimiento a priori del problema y tomar:


\begin{equation*}
\mathcal{H}_{\widetilde{h}} := \lbrace \widetilde{h}(\cdot ; w): w \in \mathbb{R}^d \rbrace
\end{equation*}



\end{frame}

\begin{frame}{Marco te\'orico del problema}

Dada $ \ell : \mathbb{R}^{d_y} \times \mathbb{R}^{d_y} \rightarrow \mathbb{R}$ una distancia en $\R^{d_y}$ entonces el objetivo se reduce a minimizar $R(w)$ donde:

\begin{equation*}
	R(w) = \int\limits_{\mathbb{R}^{d_x}\times \mathbb{R}^{d_y}} {\ell \left(h(x;w), y\right) dP(x,y)} = \mathbb{E} \left[ \ell \left( h(x;w), y \right) \right]
\end{equation*}

\pause

Al no conocer $\mathbb{P}$ se optimiza $R_n(w)$:

\begin{equation*}
R_n(w) = \frac{1}{n} \sum\limits_{i=1}^{n} {l \left( h(x;w), y\right)}
\end{equation*}

Que resulta un estimador insesgado de $R$ para cada $w \in \R^d$ por la desigualdad Hoeffding \cite{hoeffding:1962} 

\pause

No obstante, este subconjunto $\mathcal{H}$ parametrizado adem\'as debe minimizar $L(h^*, w) = \abs{R(h^*) - R_n(h_w)}$ donde $h^*$ es la funci\'on \'optima objetivo y $h_w$ es la minimizante de $R_n$ sobre el subconjunto $\mathcal{H}$.

\end{frame}

\begin{frame}{Marco te\'orico del problema}

En conclusi\'on, la obtenci\'on de dicha $h$ \'optima se separa en dos problemas no disjuntos:

\begin{enumerate}
	\item Encontrar $\mathcal{H}$ parametrizada por $w\in \R^d$ tal que $L(h^*, w^*)$ sea m\'inima, donde $w^* = arg\min\limits_{w \in \R^d}{R_n(w)}$.
	\item Dado $\mathcal{H}$ parametrizado, hallar $w^* = arg\min\limits_{w \in \R^d}{R_n(w)}$.
\end{enumerate}

\pause

El problema 1  suele tener diferentes enfoques pero ninguno estrictamente te\'orico, sino que mas bien son basados en el conocimiento a priori del problema

Nos vamos a enfocar en el problema 2 viendo diferentes algoritmos existentes para resolverlo y sus propiedades de convergencia

\end{frame}

\begin{frame}{Algoritmos de primer orden}

Comunmente para encontrar $arg\min\limits_{w \in \R^d}{F(w)}$ se utilizan algoritmos iterativos de primer orden; es decir, algoritmos que se pueden representar por $g : \R^d \rightarrow \R^d$ ta que $w_n = \underbrace{g \circ \dots \circ g}_{n} (w_0)$ y calcular $g(w)$ solo involucra calcular $F(w)$ y $\nabla F(w)$. Se suelen dividir en dos grandes grupos:

\pause

\bigskip

De tipo \textit{batch}, donde para cada iteraci\'on se utilizan todo el conjunto de datos $\sett{x_i, y_i}$. Un ejemplo de esta categor\'ia es el \textit{descenso de gradiente} (GD) dado por $g(w) = w - \alpha_n\sum\limits_{i=1}^{N} \nabla F(x_i, y_i)$.

\bigskip

De tipo \textit{estoc\'astico}, donde se elije en cada iteraci\'on al azar un subconjunto $S \subset \sett{x_i, y_i}$ para calcular $g$. Un ejemplo de esta categor\'ia es el \textit{descenso estoc\'astico de gradiente} (SG) dado por $g(w) = w - \alpha_n\nabla F(x_i, y_i)$ para un $i$ elejido al azar.

\end{frame}

\section{Convergencia de algoritmos de tipo batch}

\begin{frame}{Definiciones}


\begin{definition}[D\'ebilmente convexo]
	Decimos que $F: \R^d \rightarrow \R$, tal que $F \in C^1$ es \textit{d\'ebilmente convexo} si cumple las siguientes dos propiedades:
	
	\begin{itemize}
		\item Existe un \'unico $w^*$ tal que $F_{inf} := F(w^*) \leq F(w)$ para todo $w \in \R^n$.
		\item Para todo $\epsilon > 0$ vale que $\inf\limits_{\norm{w-w^*}^2 > \epsilon} {\left(w - w^*\right) \nabla F(w) > 0}$
	\end{itemize}
	
\end{definition}

\smallskip

\begin{definition}[Condici\'on de Robbins - Monro]
	Si consideramos el algoritmo GD, decimos que los incrementos $\sett{\alpha_k}$  cumplen la condici\'on de \textit{Robbins - Monro} (ver \cite{robbins:1951}) si:
	
	\begin{equation*}
	\sum\limits_{k=1}^{\infty} {\alpha_k} = \infty \quad \text{ y } \quad \sum\limits_{k=1}^{\infty} {\alpha_k^2} < \infty
	\end{equation*}
\end{definition}

\end{frame}

\begin{frame}{M\'as definiciones}

\begin{definition}[Condici\'on de \textit{Polyak- Lojasiewicz}]
	Decimos que una funci\'on $f:\R^d \rightarrow \R$ tal que $f \in C^1$ es $PL-$convexa, o cumple la condici\'on de \textit{Polyak- Lojasiewicz} (ver \cite{polyak:1963}, \cite{lojasiewicz:1963}) si existe $\mu >0$ tal que para todo $x \in \R^d$ vale:
	\begin{equation*}
	\frac{1}{2} \norm{\nabla f(x)}^2_2 \geq \mu \left(f(x) - f_{inf}\right)
	\end{equation*}
\end{definition}

\begin{definition}[Funci\'on Lipschitz]
	Sea $f:\R^d \rightarrow \R$ tal que $f \in C^1$, decimos que es $L$\textit{-Lipschitz} global si existe $L > 0$ tal que para todos $x,y \in \R^d$ vale:
	\begin{equation*}
	\norm{\nabla f(x) - \nabla f (y)}_2 \leq  L\norm{y-x}_2
	\end{equation*}
\end{definition}

\end{frame}

\begin{frame}{Resultados de convergencia puntual para GD}

\begin{theorem}
	Sea $F: \R^d \rightarrow \R$ tal que $F \in C^1$ la funci\'on objetivo, asumamos que $F$ es \textit{d\'ebilmente convexo}, $w^*$ su m\'inimo y que existen $A,B \geq 0$ tal que para todo $w \in \R^d$ vale que:
	
	\begin{equation*}
	\norm{\nabla F(w)}^2 \leq A + B \norm{w - w^*}^2
	\end{equation*}
	
	Luego si consideramos el algoritmo de \textit{descenso de gradiente por batch} tal que los incrementos $\sett{\alpha_k}$  cumplen la \textit{condici\'on Robbins - Monro} entonces:
	
	\begin{equation*}
	w_k \underlimitinf{k} w^*
	\end{equation*}
	
\end{theorem}

\end{frame}

\begin{frame}{Idea de la demostraci\'on}
Sea $h_k = \norm{w_k - w^*}^2$, entonces vale que $h_{k+1} - h_k \leq \alpha_k^2 \left(A + B h_k\right)$. Luego si definimos:

\begin{subequations}
	\begin{equation*}
	\mu_k = \prod\limits_{j=1}^{k-1} {\dfrac{1}{1 + \alpha_j^2B}}
	\end{equation*}
	\begin{equation*}
	h_k' = \mu_k h_k
	\end{equation*}
\end{subequations}

Uno ve que $\sett{h_k}$ converge pues $h_{k+1}' - h_{k}' \leq \alpha_k^2 A \mu_k \leq \alpha_k^2 A$. 

\pause
\smallskip

Finalmente, como podemos deducir que $\sum\limits_{k=1}^{\infty} {\alpha_k \left(w_k - w^* \right)\nabla F(w_k)} < \infty$, entonces como los incrementos cumples la condicion de Robbins Monro uno obtiene que $w_k \underlimitinf{k} w^*$.

\end{frame}

\begin{frame}{Resultados de convergencia puntual para GD}

\begin{theorem}
	Sea $F: \R^d \rightarrow \R$ la funci\'on objetivo tal que $F \in C^1$, $F$ es \textit{L-Lipshitz} y \textit{PL-convexa}; entonces el algortimo \textit{descenso de gradiente por batch} con incremento fijo $\alpha_k = \frac{1}{L}$ cumple:
	\begin{equation*}
	F(w_k) - F_{inf} \leq \left(1 - \frac{\mu}{L}\right)^k \left(F(w_1) - F_{inf}\right)
	\end{equation*}
\end{theorem}

\end{frame}

\begin{frame}{Idea de la demostraci\'on}

Por las implicancias de ser $L-$Lipschitz y $PL-$convexa tenemos:

\begin{equation*}
F(w_{k+1}) - F(w_k) \leq -\frac{1}{2L} \norm{\nabla F(w_k)}_2^2 \leq - \frac{\mu}{L} \left(F(w_k) - F_{inf}\right)
\end{equation*}

Luego:

\begin{equation*}
F(w_{k+1}) - F_{inf} \leq \left(1 - \frac{\mu}{L} \right) \left(F(w_k) - F_{inf}\right) \leq \left(1 - \frac{\mu}{L}\right)^k \left(F(w_1) - F_{inf}\right)
\end{equation*}

\end{frame}


\begin{frame}{Caso no convexo}

\textbf{{Bajo qu\'e casos el algoritmo GD converge (en alguna forma) con objetivos no convexos?}}

\pause

Para responder esto, sea $g : M  \rightarrow M$ la f\'ormula del algoritmo de primer orden en $M \subset \R^N$ una subvariedad sin borde de dimensi\'on $d$.

\begin{definition}
	Sea $f : M \rightarrow \R$ tal que $f \in C^2$ y $x^* \in \R^d$, luego decimos que $x^*$ es un \textit{punto silla estricto} de $f$ si es un punto cr\'itico y $\lambda_{min} \left(\nabla ^2 f(x^*)\right) < 0$ 
	
	Notaremos $M^*$ al conjunto de puntos silla estrictos de $f$.
	
\end{definition}

\pause

\begin{definition}
	Sea:
	\begin{equation*}
	\puntosfijos := \sett{x \ : \ g(x) = x \quad \max\limits_{i}\abs{\lambda_i \left(Dg(x)\right)} > 1}
	\end{equation*}
	
	A este conjunto lo llamaremos el conjunto de \textit{puntos fijos inestables}
\end{definition}



\end{frame}

\begin{frame}{Caso no convexo}

\begin{theorem}
	Sea $g \in C^1(M)$ tal que $\det\left(Dg(x)\right) \neq 0$ para todo $x \in M$, luego el conjunto de puntos iniciales que convergen por $g$ a un punto fijo inestable tiene medida cero:
	\begin{equation*}
	\mu \left(\sett{x_0 \ \colon \ \Biglim{k}{g^k(x_0) \in \mathcal{A}_g^{*}}}\right) = 0
	\end{equation*}
\end{theorem}

\pause

\begin{corollary}
	Bajo las mismas hip\'otesis si agregamos que $M^* \subseteq \mathcal{A}_g^{*}$ entonces $\mu(\sett{x_0 \ \colon \ \Biglim{k}{g^k(x_0) \in M^*}}) =0$
\end{corollary}

\end{frame}

\begin{frame}{Algoritmos de tipo batch est\'andar}
Ademas del algoritmo GD, en la optimizaci\'on de tipo batch existen dos algoritmos muy usuales:

\pause
\medskip

El algoritmo de punto pr\'oximo esta dado por la iteraci\'on:

\begin{equation*}
x_{k+1} = g(x_k) \stackrel{\triangle}{=} \arg \min\limits_{z \in M}{f(z) + \dfrac{1}{2\alpha}\norm{x_k - z}_{2}^{2}}
\end{equation*}

\pause
\medskip

Por otro lado, si definimos $g_i(x) = x - \alpha \Bigsum{j \in S_i}{e_j^T \nabla f(x)}$ entonces el algoritmo de descenso de coordenadas por bloques esta dado por:

	\begin{equation*}
	x_{k+1} = g(x_k) \stackrel{\triangle}{=} g_b \circ g_{b-1} \circ \dots \circ g_1(x_k)
	\end{equation*}





\end{frame}

\begin{frame}{Un marco de demostraci\'on com\'un}
\begin{theorem}
	Sea $F: \R^d \rightarrow \R$ tal que $F \in C^2$ la funci\'on objetivo con Hessiano acotado con constante $L$, $w^*$ alg\'un m\'inimo local de $F$; entonces el algoritmo \textit{descenso de gradiente por batch} con incremento fijo $\alpha < \frac{1}{L}$ cumple:
	
	\begin{equation*}
	w_k \xrightarrow[k \rightarrow \infty]{c.t.p.} w^*
	\end{equation*}
	
\end{theorem}

\smallskip

\begin{theorem}
	Sea $F: \R^d \rightarrow \R$ tal que $F \in C^2$ la funci\'on objetivo con Hessiano acotado con constante $L$, $w^*$ alg\'un m\'inimo local de $F$; entonces el algoritmo \textit{punto pr\'oximo } con incremento fijo $\alpha < \frac{1}{L}$ cumple:
	
	\begin{equation*}
	w_k \xrightarrow[k \rightarrow \infty]{c.t.p.} w^*
	\end{equation*}
	
\end{theorem}

\end{frame}

\begin{frame}{Un marco de demostraci\'on com\'un}

\begin{theorem}
	Sea $F: \R^d \rightarrow \R$ tal que $F \in C^2$  la funci\'on objetivo con Hessiano acotado por bloques con constante $L_b$, $w^*$ alg\'un m\'inimo local de $F$; entonces el algoritmo \textit{descenso de gradiente por coordenadas} con incremento fijo $\alpha < \frac{1}{L_b}$ cumple:
	
	\begin{equation*}
	w_k \xrightarrow[k \rightarrow \infty]{c.t.p.} w^*
	\end{equation*}
	
\end{theorem}
\end{frame}

\begin{frame}{Idea de las demostraciones}

En los tres casos las hip\'otesis llevan a demostrar que:

\begin{enumerate}
	\item 	$det\left(Dg\right)(x) \neq 0$
	\item $M^* \subset \puntosfijos$
\end{enumerate}

Luego con eso uno concluye que $\mu(\sett{x_0 \ \colon \ \Biglim{k}{g^k(x_0) \in M^*}}) =0$ por lo que el conjunto de puntos iniciales tales que el algoritmo en cuesti\'on converge a un punto silla estricto en $0$. Como ya sabemos que el algoritmo no converge a m\'aximos locales se concluye que:

	\begin{equation*}
w_k \xrightarrow[k \rightarrow \infty]{c.t.p.} w^*
\end{equation*}

Donde $w^*$ es m\'inimo local.

\end{frame}

\begin{frame}{Convergencia exponencial de GD}
\textbf{Â¿El descenso de gradiente inicializado aleatoriamente generalmente escapa de los puntos de silla en tiempo polinomial?}

\pause

\begin{definition}
	Dado $B \in \R^d$ decimos que $B \in poly(d)$ si existe $p \in \R[X]$ tal que $p(d) = B$.
	Asimismo decimos que una iteraci\'on de un algoritmo $w_k$ esta a $\Omega(f(k))$ de $w^*$ si existe $K \in \N$ tal que $\abs{w^* - w_k} \geq Kf(k)$
\end{definition}

\pause

\begin{theorem}
	Consideremos el algoritmo \textit{descenso de gradiente por batch} con $w_0$ elegido uniformemente en $[-1,1]^d$; luego existe $F : \R^d \mapsto \R$ funci\'on objetivo $B-$acotada, $l-$Lipshitz, $\mu-$Lipshitz en el Hessiano con $B,l,\mu \in \text{poly}(d)$ tal que si $\alpha_k = \alpha \leq \frac{1}{l}$ entonces $w_k$ va a estar a $\Omega(1)$ de cualquier m\'inimo para todo $k \leq e^{\Omega(d)}$
\end{theorem}

\end{frame}

\begin{frame}{Intuici\'on acerca de la demostraci\'on: Parte 1}

\textbf{Escapar de dos puntos silla consecutivos}

\bigskip
\pause

	Sean $L > \gamma > 0$ y $f \in [0,3] \times [0,3]$ dada por:
	
	\begin{equation*}
	f(x_1, x_2) = \left\lbrace \begin{array}{cc}
	- \gamma x_1^2 + Lx_2^2 & \text{ si } (x_1,x_2) \in [0,1] \times [0,1] \\
	L \left(x_1 - 2\right)^2 - \gamma x_2^2 & \text{ si } (x_1,x_2) \in [1,3] \times [0,1] \\
	L \left(x_1 - 2\right)^2 + L \left(x_2 - 2\right)^2 & \text{ si } (x_1,x_2) \in [1,3] \times [1,3] \\
	\end{array} \right.
	\end{equation*}
	
	\pause
	\bigskip
	
	Notemos que $f$ tiene dos puntos silla estrictos en $(0,0)$ y $(2,0)$, mientras que tiene un \'optimo en $(2,2)$. 
	
\end{frame}
\begin{frame}{Intuici\'on acerca de la demostraci\'on: Parte 2}
	
	Sean $U = [0,1]^2$, $V= [1,3] \times [0,1]$ y $W = [1,3]^2$ entornos respectivos de los tres puntos cr\'iticos, supongamos que $w_0 = \left(x^0_1, x^0_2\right) \in U$ y definamos:
	
	\begin{subequations}
		\begin{equation*}
		k_1 = \inf\limits_{x^k_1 \geq 1}{k} = \min\limits_{x^k_1 \geq 1}{k}
		\end{equation*}
		\begin{equation*}
		k_2 = \inf\limits_{x^k_2 \geq 1}{k} = \min\limits_{x^k_2 \geq 1}{k}
		\end{equation*}
	\end{subequations}
	
	\pause
	\bigskip
	
	Notemos que como la direcci\'on de escape en $(0,0)$ es por $x_1$ y \textit{luego} por $x_2$ (por el cambio de comportamiento de $f$) podemos concluir que $k_1,k_2$ estan bien definidos y que $k_2 \geq k_1 \geq 0$.
	
	\medskip
	Vamos a probar que $k_2 = Ck_1$ con $C>1$.
	
\end{frame}
\begin{frame}{Intuici\'on acerca de la demostraci\'on: Parte 3}
	
Las iteraciones de GD en este caso van a ser:
	
	\begin{equation*}
	\begin{array}{rcl}
	\left(x_1^{k+1}, x^{k+1}_2\right) & =  &\left\lbrace\begin{array}{c}
	\left(\left(1 + 2\alpha \gamma \right)x^k_1, \left(1 - \alpha 2L\right)x^k_2\right) \\ \text{ si } x_1 \leq 1\\
	\left(\left(1 - 2L \alpha \right)x^k_1 + 4L \alpha, \left(1 + 2 \alpha \gamma \right)x^k_2\right) \\ \text{ si } x_1 \geq 1 \ , \ x_2 \leq 1 \\
	\left(\left(1 - 2L \alpha \right)x^k_1 + 4L \alpha, \left(1 - 2L \alpha \right)x^k_2 + 4L \alpha\right)  \\ \text{ si } x_1 \geq 1 \ , \ x_2 \geq 1
	\end{array}\right.
	\end{array}
	\end{equation*}
	
	\end{frame}
\begin{frame}{Intuici\'on acerca de la demostraci\'on: Parte 4}
	
	Luego evaluando en $k_1$ y $k_2$:
	
	\begin{equation*}
	\begin{array}{rcl}
	x^{k_1}_1 & = & \left(1 + 2 \alpha \gamma\right)^{k_1} x^0_1 \\
	x^{k_1}_2 & = & \left(1 - 2 \alpha L\right)^{k_1} x^0_1 \\
	&&\\
	x^{k_2}_1 & = & \left(1 - 2L\alpha\right)^{k_2 - k_1}\left(1 + 2 \alpha \gamma\right)^{k_1} x^0_1 + K\geq 1 \quad K \text{ constante}\\
	x^{k_2}_2 & = & \left(1 + 2 \alpha \gamma\right)^{k_2-k_1}\left(1 - 2 \alpha L\right)^{k_1} x^0_2\geq 1 \\
	\end{array}
	\end{equation*}
	
	\medskip
	
	concluimos que:
	
	\medskip
	\begin{equation*}
	k_2 \geq \dfrac{2 \alpha \left(L + \gamma\right)k_1 - \log\left(x_2^0\right)}{2 \alpha \gamma} \geq \dfrac{L + \gamma}{\gamma} k_1 
	\end{equation*}
	
	\end{frame}
	
	\begin{frame}{Intuici\'on acerca de la demostraci\'on: Conclusiones}
	Esta $f$ que presentamos tiene varios problemas:
	
	\begin{enumerate}
		\item No es continua ni mucho menos $C^2$
		\item No podemos asegurar que $f$ sea $l-$Lipschitz o $\mu-$Lipschitz en el hessiano
		\item Los puntos cr\'iticos estan en el borde del dominio, lo que no es ideal
		\item No est\'a definida en todo $\R^d$
	\end{enumerate}
	
	\pause
	\bigskip
	
	La clave va a ser usar splines para resolver los primeros puntos, espejar $f$ para hacer los puntos extremales interiores, asignar $d$ puntos cr\'iticos similares para generar el tiempo exponencial en $d$ y extender esa funci\'on $\tilde{f}$ a $\R^d$ con el Teorema de extensi\'on de Whitney. Aunque la demostraci\'on es larga y tediosa, la idea clave es la vista aqu\'i.
\end{frame}

\section{Algoritmos estoc\'asticos}

\begin{frame}{Descenso estoc\'astico}
En el contexto estoc\'astico vamos a analizar el algoritmo de descenso estoc\'astico generalizado (DE) dado por:

\begin{algorithm*}[H]
	\caption{Descenso Estocastico (DE)}
	\textbf{Input:} $w_1 \in \R^d$ el inicio de la iteraci\'on, $\sett{\upxi_{k}} $ iid \\
	\For{$k \in \N$}{
		Generar una muestra de la variable aleatoria $\upxi_k$ \\
		Calcular el vector estoc\'astico $g(w_k, \upxi_k)$ \\
		Elegir $\alpha_k >0$ \\
		$w_{k+1} \leftarrow w_k - \alpha_kg(w_k, \upxi_k)$
	}
\end{algorithm*}

Donde $g(w_k, \upxi_k)$ puede ser varias estimaciones del gradiente como por ejemplo:

\begin{equation*}
g(w_k, \upxi_k) = \left\lbrace
\begin{aligned}
\nabla f(w_k, \upxi_k) \\
\frac{1}{n_k} \sum\limits_{i=1}^{n_k} {\nabla f (w_k, \upxi_{k,i})}
\end{aligned}
\right.
\end{equation*}

\end{frame}

\begin{frame}{Lemas fundamentales}

Definamos ahora $\expectationsub{\upxi_k}{.} := \mathbb{E}_{P_k}\left[. \vert w_k\right]$ la esperanza condicional bajo la distribuci\'on de $\upxi_k$ dado $w_k$.

\medskip


\begin{lemma}
	Si $F$ es Lipschitz , entonces las iteraciones del algoritmo DE satisfacen que para todo $k \in N$:
	
	\begin{equation*}
	\begin{aligned}
	\expectationsub{\upxi_{k}}{F(w_{k+1})} - F(w_k) \leq & - \alpha_k \nabla F(w_k) ^T \expectationsub{\upxi_{k}}{g(w_k, \upxi_{k})} \\ & + \frac{1}{2} \alpha_k^2 \expectationsub{\upxi_{k}}{\norm{g(w_k, \upxi_{k})}^2_2}
	\end{aligned}
	\end{equation*}
	
\end{lemma}
\pause
\medskip

	Notemos que si $g(w_k, \upxi_{k})$ es un estimador insesgado de $\nabla F (w_k)$ entonces del lema:
	
	\begin{equation*}
	\expectationsub{\upxi_{k}}{F(w_{k+1})} - F(w_k) \leq - \alpha_k \norm{\nabla F(w_k)}^2 + \frac{1}{2} \alpha_k^2 \expectationsub{\upxi_{k}}{\norm{g(w_k, \upxi_{k})}^2_2}
	\end{equation*}
	

\end{frame}

\begin{frame}{Lemas fundamentales}



\begin{hyp}[Acotaciones al primer y segundo momento de $g$]
	Supongamos que dada $F$ funci\'on objetivo y $g$ la estimaci\'on del gradiente en DE vale:
	
	\begin{enumerate}
		\item Existe $U \subset \R^d$ tal que $\sett{w_k} \subset U$ y que existe $F_{inf}$ tal que $F\vert_U \geq F_{inf}$
		\item Existen $\mu_G \geq \mu \geq 0$ tal que para todo $k \in N$ valen:
		
		\begin{subequations}
			\begin{equation*}
			\nabla F(w_k)^T \expectationchik{g(w_k, \upxi_{k})} \geq \mu \norm{\nabla F(w_k)}_2^2
			\end{equation*}
			Y
			\begin{equation*}
			\norm{\expectationchik{g(w_k, \upxi_{k})}}_2 \leq \mu_G \norm{\nabla F(w_k)}_2
			\end{equation*}
		\end{subequations}
		\item 	Existen $M, M_V \geq 0$ tal que para todo $k \in \N$:
		\begin{equation*}
		\variancechik{g(w_k, \upxi_{k})} \leq M + M_V \norm{\nabla F (w_k)}_2^2
		\end{equation*}
		
	\end{enumerate}
	
\end{hyp}

\end{frame}

\begin{frame}{Lemas fundamentales}

	Notemos que si vale la hip\'otesis en los momentos de $g$ entonces:
	
	\begin{equation*}
	\expectationchik{\norm{g(w_k, \upxi_{k})}_2^2} \leq M + M_G\norm{\nabla F(w_k)}_2^2  \qquad M_G:= M_V + \mu_G^2 \geq \mu^2 \geq 0
	\end{equation*}

\bigskip
\pause

\begin{lemma}
	Bajo la hip\'otesis en los momentos de $g$ y si $F$ es Lipszhits entonces las iteraciones del algoritmo DE satisfacen para todo $k \in \N$:
	
	\begin{subequations}
		\begin{equation*}
		\expectationchik{F(w_{k+1})} - F(w_k) \leq -\mu \alpha_k \norm{\nabla F(w_k)}_2^2 + \frac{1}{2} \alpha_k^2 L \expectationchik{\norm{g(w_k, \upxi_{k})}_2^2}
		\end{equation*}
		\begin{equation*}
		\expectationchik{F(w_{k+1})} - F(w_k) \leq - \left( \mu - \frac{1}{2} \alpha_k L M_G \right)\alpha_k \norm{\nabla F(w_k)}_2^2 + \frac{1}{2} \alpha_k^2 L M
		\end{equation*}
	\end{subequations}
	
\end{lemma}

\end{frame}

\begin{frame}{Convergencia en L1}
\begin{theorem}
	Sea $F: \R^d \rightarrow \R$ tal que $F \in C^1$ la funci\'on objetivo tal que existe $F_{inf}$ valor m\'inimo, $F$ es \textit{L-Lipshitz}, $F$ es \textit{fuertemente convexa} y supongamos adem\'as que $g$ tiene \textit{varianza acotada}; entonces el algoritmo \textit{descenso estoc\'astico de gradiente generalizado} con incremento fijo $0  <  \alpha_k = \alpha \leq \dfrac{\mu}{LM_G}$ cumple:
	
	\begin{equation*}
	\expectation{F(w_k) - F_{inf}} \underlimitinf{k} \dfrac{\alpha LM}{2 c \mu}
	\end{equation*}
	
\end{theorem}

\end{frame}

\begin{frame}{Esquema de la demostraci\'on}
	Usando que $F$ es Lipschitz y fuertemente convexa con la condici\'on sobre $\alpha$ tenemos para todo $k \in \N$ vale:

\begin{equation*}
\expectationchik{F(w_{k+1}) - F(w_k)} \leq - \alpha \mu c \left(F(w_k) - F_{inf} \right)+ \frac{1}{2} \alpha ^2 LM 
\end{equation*}

Luego si restamos $F_{inf}$ y tomamos esperanza total:

\begin{equation*}
\expectation{F(w_{k+1}) - F_{inf}} - \dfrac{\alpha L M}{2 c \mu }   \left(1 - \alpha c \mu  \right)  \left(\expectation{F(w_k) - F_{inf}}  -  \dfrac{\alpha L M}{2 c \mu }  \right)
\end{equation*}

Luego deducimos inductivamente que:

\begin{equation*}
\expectation{F(w_{k+1}) - F_{inf}} - \dfrac{\alpha L M}{2 c \mu } \leq \left(1 - \alpha c \mu \right)^{k} \left(F(w_1) - F_{inf} - \dfrac{\alpha LM}{2 c \mu} \right)
\end{equation*}
\end{frame}

\begin{frame}{Convergencia en L1}

\begin{theorem}
	Sea $F: \R^d \rightarrow \R$ tal que $F \in C^1$ la funci\'on objetivo tal que existe $F_{inf}$ valor m\'inimo, $F$ es \textit{L-Lipshitz}, $F$ es \textit{fuertemente convexa}; supongamos adem\'as que $g$ tiene \textit{varianza acotada} y que los incrementos $\alpha_k$ cumplen:
	
	\begin{equation*}
	\alpha_k =  \dfrac{\beta}{\gamma + k} \quad \ \text{ para alg\'un } \ \beta > \frac{1}{c \mu} \  \text{ y } \ \gamma > 0 \  \text{ tal que } \ \alpha_1 \leq \dfrac{\mu}{L M_G} 
	\end{equation*}
	
	Luego el algoritmo \textit{descenso estoc\'astico de gradiente generalizado} cumple::
	
	\begin{equation*}
	\expectation{R(w_k) - R^*} = \mathcal{O} \left(\frac{1}{k}\right)
	\end{equation*}
	
\end{theorem}
\end{frame}

\begin{frame}{Esquema de la demostraci\'on}
	Usando que $F$ es Lipschitz y fuertemente convexa con la condici\'on sobre $\alpha$ tenemos para todo $k \in \N$ vale:

\begin{equation*}
\expectationchik{F(w_{k+1})} - F(w_k) \leq  - \alpha_k c \mu \left(F(w_k) - F(w_*)\right) + \frac{1}{2} \alpha_k^2 L M
\end{equation*}

Luego restando $F_{inf}$, tomando esperanza y reordenando vale:

\begin{equation*}
\expectation{F(w_{k+1}) - F_{inf}} \leq \left(1 - \alpha_k c \mu \right) \expectation{F(w_{k}) - F_{inf}}  + \frac{1}{2} \alpha_k^2 L M
\end{equation*}

Luego inductivamente:

\begin{equation*}
\expectation{F(w_{k+1}) - F_{inf}} \leq \dfrac{\eta}{\gamma + k + 1}
\end{equation*}
\end{frame}

\begin{frame}{Convergencia en L1}
\begin{theorem}
	Sea $F: \R^d \rightarrow \R$ tal que $F \in C^1$ la funci\'on objetivo tal que existe $F_{inf}$ valor m\'inimo, $F$ es \textit{L-Lipshitz}, $F$ es \textit{fuertemente convexa}; supongamos adem\'as que existe $M \geq 0$ y $\xi \in (0,1)$ tal que para todo $k \in \N$:
	
	\begin{equation*}
	\variancechik{g(w_k, \upxi_{k})} \leq M \xi^{k-1}
	\end{equation*}
	
	Luego el algoritmo \textit{descenso estoc\'astico de gradiente generalizado} con incremento fijo $0  < \alpha_k = \alpha \leq \min\sett{\dfrac{\mu}{L \mu_G^2}, \frac{1}{ \mu}} $ cumple:
	
	\begin{equation*}
	\expectation{R(w_k) - R^*} = \mathcal{O} \left(\rho^{k}\right)
	\end{equation*}
	
\end{theorem}
\end{frame}

\begin{frame}{Esquema de la demostraci\'on}
	Por el lema, la condici\'on de $\alpha$ y las hip\'otesis sobre $F$ y $g$ vale que:
	
\begin{equation*}
\expectation{F(w_{k+1}) - F_{inf}} \leq \left(1 - c \mu \alpha\right) \expectation{F(w_k) - F_{inf}} + \frac{1}{2} \alpha^2 LM \xi^{k-1}
\end{equation*}

E inductivamente se prueba que:

\begin{equation*}
\expectation{F(w_{k+1}) - F_{inf}}  \leq  \omega \rho^{k}
\end{equation*}
\end{frame}

\begin{frame}{Convergencia en L1}
\begin{theorem}
	Sea $F: \R^d \rightarrow \R$ tal que $F \in C^1$ la funci\'on objetivo , $F$ es \textit{L-Lipshitz} y supongamos adem\'as que $g$ tiene \textit{varianza acotada}. Luego el algoritmo \textit{descenso estoc\'astico de gradiente generalizado} con incremento fijo $0  < \alpha_k = \alpha \leq \dfrac{\mu}{LM_G} $ cumple:
	
	\begin{equation*}
	\expectation{\dfrac{1}{K}\sum\limits_{k=1}^{K} {\norm{\nabla F (w)_k}^2}} \underlimitinf{k}  \dfrac{\alpha LM}{\mu}
	\end{equation*}
	
\end{theorem}
\end{frame}

\begin{frame}{Esquema de la demostraci\'on}
	Recordemos del lema si tomamos esperanza total e imponemos la condici\'on de $\alpha$ tenemos:

\begin{equation*}
\expectation{F(w_{k+1})} - \expectation{F(w_k)}  \leq  - \frac{1}{2}\alpha \mu \expectation{\norm{\nabla F(w_k)}_2^2} + \frac{1}{2} \alpha^2 LM
\end{equation*}

Luego si usamos la hip\'otesis de $g$ y que $F_{inf} \leq \expectation{F(w_k)}$ para todo $k \in \N$ vale:

\begin{equation*}
		\expectation{\sum\limits_{k=1}^{K} {\norm{\nabla F (w)_k)}_2^2}} \leq \dfrac{K \alpha LM}{\mu} + \dfrac{2(F(w_1) - F_{inf})}{\mu \alpha}
\end{equation*}
\end{frame}

\begin{frame}{Convergencia en L1}
\begin{theorem}
	Sea $F: \R^d \rightarrow \R$ tal que $F \in C^2$ la funci\'on objetivo, $F$ es \textit{L-Lipshitz} y $w \mapsto \norm{\nabla F (w)}_2^2$ sea \textit{L-Lipshitz}; supongamos adem\'as que $g$ tiene \textit{varianza acotada} y que los incrementos cumplen la \textit{condici\'on de Robbins Monro}. Luego el algoritmo \textit{descenso estoc\'astico de gradiente generalizado} con incrementos decrecientes cumple:
	
	\begin{equation*}
	\lim\limits_{k \rightarrow \infty} \expectation{\norm{\nabla F (w_k)}^2} = 0
	\end{equation*}
	
\end{theorem}
\end{frame}

\begin{frame}{Idea de la demostraci\'on}
Sea $G(w) := \norm{\nabla F(w)}_2^2$ y sea $L_G$ la constante de Lipshitz de $\nabla G(w) = 2 \nabla^2 F(w) \nabla F(w)$, luego:

\begin{equation*}
G(w_{k+1}) - G(w_k) \leq  - \alpha_k \nabla G(w_k)^T g(w_k, \upxi_{k}) + \frac{1}{2} \alpha_k L_G  \norm{g(w_k, \upxi_{k})}_2^2
\end{equation*}

Si tomamos esperanza condicional a $\upxi_{k}$ y usamos que $F$ es Lipschitz y $g$ tiene momentos acotados entonces:

\begin{footnotesize}
\begin{equation*}
\begin{aligned}
\expectationchik{G(w_{k+1}) - G(w_k)} & \leq &   2 \alpha_k \norm{\nabla F(w_k)}_2 \norm{\nabla^2 F(w_k)}_2 \norm{\expectationchik{g(w_k, \upxi_{k})}}_2 +  \\
&& \frac{1}{2} \alpha_k^2 L_G \expectationchik{\norm{g(w_k, \upxi_{k})}^2_2} \\
& \leq & 2 \alpha_k L \mu_G \norm{\nabla F (w_k)}_2^2 + \\
&& \frac{1}{2} \alpha_k^2 L_G\left(M + M_V \norm{\nabla F(w_k)}_2^2\right)
\end{aligned}
\end{equation*}
\end{footnotesize}

\end{frame}
\begin{frame}{Idea de la demostraci\'on: Continuaci\'on}
Tomando esperanza total:

\begin{footnotesize}
\begin{equation*}
\begin{aligned}
\expectation{G(w_{k+1})} - \expectation{G(w_k)} \leq & 2 \alpha_k L \mu_G \expectation{\norm{\nabla F (w_k)}_2^2} \\  & + \frac{1}{2} \alpha_k^2 L_G\left(M + M_V \expectation{\norm{\nabla F(w_k)}_2^2}\right)
\end{aligned}
\end{equation*}
\end{footnotesize}
	
Luego:

\begin{footnotesize}
\begin{equation*}
\lim\limits_{N \rightarrow \infty} { {2 L \mu_G \sum\limits_{k=K}^{K+N}\expectation{\alpha_k\norm{\nabla F (w_k)}_2^2}+  \frac{1}{2} L_G\left(M\sum\limits_{k=K}^{K+N}\alpha_k^2 + M_V \sum\limits_{k=K}^{K+N}\expectation{\alpha_k^2\norm{\nabla F(w_k)}_2^2}\right)} } = 0
\end{equation*}
\end{footnotesize}

Se concluye que $\expectation{G(w_k)}$ debe ser convergente, y por los teoremas anteriores tenemos $\expectation{\norm{\nabla F(w_k)}_2^2} = \expectation{G(w_k)} \rightarrow 0$

\end{frame}

\begin{frame}{Convergencia c.t.p.}
\begin{theorem}
	Sea $F: \R^d \rightarrow \R$ tal que $F \in C^1$ la funci\'on objetivo tal que existe $F_{inf}$ valor m\'inimo, $F$ es \textit{d\'ebilmente convexo}; supongamos adem\'as que $g$ tiene \textit{varianza acotada} y que los incrementos cumplen la \textit{condici\'on de Robbins Monro}. Luego el algoritmo \textit{descenso estoc\'astico de gradiente generalizado} con incremento decrecientes cumple:
	
	\begin{subequations}
		\begin{equation*}
		w_k \xrightarrow[k \rightarrow \infty]{c.t.p.} w^*
		\end{equation*}
		\begin{equation*}
		\left(w_k - w^*\right)^T \nabla F(w_k) \xrightarrow[k \rightarrow \infty]{c.t.p.}  0
		\end{equation*}
	\end{subequations}
	
\end{theorem}
\end{frame}

\begin{frame}{Convergencia c.t.p. : Hip\'otesis}
\begin{hyp}
	Sea $F: \R^d \rightarrow \R$  funci\'on objetivo y  $g$ un estimador insesgado de $\nabla F$ tal que ambos cumplen:
	
	\begin{enumerate}
		\item $F \in C^3$
		\item Existe $w^* \in \R^d$ tal que $F_{inf} = F(w^*) \leq F(w)$ para todo $w \in U$ entorno.
		\item $F(w) \geq 0$ para todo $w \in \R^d$
		\item Los incrementos cumplen la \textit{condici\'on de Robbins Monro}
		\item Existe $B_2 \geq 0$ tal que:
		
		\begin{equation*}
		\expectation{\norm{g(w_k, \upxi_{k})}^2} \leq B_2 \norm{w}^2
		\end{equation*}		
		\end{enumerate}
\end{hyp}	
\end{frame}
\begin{frame}{Convergencia c.t.p. : Hip\'otesis continuaci\'on}
\begin{hyp}
	\begin{enumerate}
		\setcounter{enumi}{5}
		\item Para $j=3, 4$ existen $A_j,B_j \geq 0$ tal que:
		
		\begin{equation*}
		\expectation{\norm{g(w_k, \upxi_{k})}^j} \leq A_j + B_j \norm{w}^j
		\end{equation*}
		
		\item  Existe $D > 0$ tal que:
		
		\begin{equation*}
		\inf\limits_{(w)^2 > D} {w^T \nabla F(w)} >0
		\end{equation*}
	\end{enumerate}
	
\end{hyp}
\end{frame}

\begin{frame}{Convergencia c.t.p. : Teorema}
\begin{theorem}
	Bajo todas las hip\'otesis mencionadas anteriormente, el algoritmo \textit{descenso estoc\'astico de gradiente generalizado} con incrementos decrecientes cumple:
	
	\begin{subequations}
		\begin{equation*}
		F(w_k) \xrightarrow[k \rightarrow \infty]{c.t.p.} \ F_{\infty}
		\end{equation*}
		\begin{equation*}
		\nabla F(w_k) \xrightarrow[k \rightarrow \infty]{c.t.p.} 0
		\end{equation*}
	\end{subequations}
\end{theorem}	
\end{frame}

\section{References}
\begin{frame}[allowframebreaks]{References}
\begin{thebibliography}{99}
{\fontsize{10}{10} \selectfont


\beamertemplatearticlebibitems

\bibitem{BBI} 
 L. Berezansky, E. Braverman, L.  Idels,  
 {\em Nicholson's blowflies differential equation revisited: main results and open problems}. Appl. Math. Model,  {\bf 34}, (2010) 1405--1417.
 
 \beamertemplatearticlebibitems

 \bibitem{FM}
H. Freedman, P. Moson, {\em Persistence definitions and their connections}, Proc. Am. Math. Soc. 109, 4 (1990), 1025--1033. 
 
\beamertemplatearticlebibitems

\bibitem{F}
A. Fonda, 
{\em Uniformly persistent semidynamical systems}
Proc. Am. Math. Soc.
104, 1 (1988)

\beamertemplatearticlebibitems

\bibitem{ST}
H. Smith, H. Thieme, {\em Dynamical Systems
and Population
Persistence}. 
American Mathematical Society, 2011. 

\beamertemplatearticlebibitems

 \bibitem{SY} 
  J. So, J. S. Yu, {\em Global attractivity and uniform persistence in Nicholson's blowflies}, Diff. Eqns. Dynam. Syst. {\bf 2} (1) (1994) 11--18
  
}

\end{thebibliography}
\end{frame}

\begin{frame}
 \begin{center}
  \LARGE{{\bf Thanks for your attention!}}
 \end{center}
\end{frame}

\end{document}
