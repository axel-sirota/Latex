%********************************************************************
% Appendix
%*******************************************************
% If problems with the headers: get headings in appendix etc. right
%\markboth{\spacedlowsmallcaps{Appendix}}{\spacedlowsmallcaps{Appendix}}
\chapter{Ap\'endice}\label{ch: apendice}



\section{Proposiciones enunciadas}

\begin{theorem}
	\label{theorem: splines 1}
	Dados $y_0 < y_1$, valores $f(y_0), f(y_1)$ y sus derivadas $f'(y_0), f'(y_1)$ con $f'(y_0)<0$ el \textit{polinomio c\'ubico interpolante de Hermite} se define por:
	
	\begin{equation}
	p(y) = c_0 + c_1 \delta_y + c_2 \delta_y^2 + c_3 \delta_y^3
	\end{equation}
	
	Donde:
	
	\begin{equation*}
		\begin{array}{rcl}
		y & \in & [y_0, y_1] \\
		c_0 & = & f(y_0) \\
		c_1 & = & f'(y_0) \\
		c_2 & = & \dfrac{3S - f'(y_0) - 2f'(y_0)}{y_1 - y_0} \\
		c_3 & = & - \dfrac{2S - f'(y_1) - f'(y_0)}{\left(y_1 - y_0\right)^2} \\
		\delta_y & = & y - y_0 \\
		S & = & \dfrac{f(y_1) - f(y_0)}{y_1 - y_0}
		\end{array}
	\end{equation*}
	
	Y $p(y)$ satisface $p(y_0) = f(y_0), \ p(y_1) = f(y_1), \ p'(y_0) = f'(y_0)$ y $p'(y_1)=f'(y_1)$; adem\'as si $f(y_1) < f(y_0) < 0$ y:
	
	\begin{equation*}
		f'(y_1) \geq \dfrac{3 \left(f(y_1) - f(y_0)\right)}{y_1 - y_0}
	\end{equation*}
	
	Entonces para $y \in [y_0, y_1]$ vale que $p(y) \in \left[f(y_1), f(y_0)\right]$
	
\end{theorem}

\begin{proof}
	Ver \cite{dougherty:1989}
\end{proof}

\begin{theorem}
	\label{theorem: Extension de Whitney mejorado}
	Sea $E \subset \R^d$ un compacto y $f \in C^m(E)$. Si dotamos a $C^m(E)$ de la norma $\norm{f}_{C^m} = \sup\sett{\norm{\partial^{\alpha}f\vert_E }_{\infty} \tq \abs{\alpha} < m}$ entonces existe $T \in L\left(C^m(E), C^m\left(\R^d \right) \right)$ extensi\'on de $f$ tal que $T(f) \vert_E = f$ y $T(f) \in C^{\infty}(E^c)$. Es m\'as, $\norm{T} \leq C(m) d^{\frac{5m}{2}}$.
\end{theorem}

\begin{proof}
	Ver \cite{cheng:2015}
\end{proof}

\section{Demostraciones}

\begin{proof}{[De \ref{lemma: Convergencia de sucesiones positivas acotadas sumables}]}
	Definamos:
	
	\begin{subequations}
		\begin{equation}
		S^+_t := \sum\limits_{k=1}^{t-1} {\left(u_{k+1} - u_k\right)_+}
		\end{equation}
		\begin{equation}
		S^-_t := \sum\limits_{k=1}^{t-1} {\left(u_{k+1} - u_k\right)_-}
		\end{equation}
	\end{subequations}
	
	Donde recordemos que $(x)_{\pm} = x1_{\sett{\R_{\pm}}}$. Como sabemos que $ {\left(u_{k+1} - u_k\right)_+} \geq 0$ para todo $k \in \N$ entonces $S_t^+ \nearrow S_{\infty}^+$; asimismo,  $ {\left(u_{k+1} - u_k\right)_-} \leq 0$ para todo $k \in \N$ entonces $S_t^- \leq 0$. Por lo tanto:
	
	\begin{subequations}
		\begin{equation}
		0 \leq u_k = u_0 + S_k^+ + S_k^- \leq u_0 + S_{\infty}^+
		\end{equation}
		\begin{equation}
		-u_0 - S_{\infty}^+ \leq S_k^- \leq 0
		\end{equation}
	\end{subequations}
	
	Luego como $S_{k+1}^- \leq S_k^-$ conclu\'imos que $S_{k}^- \searrow S_{\infty}^-$. Por lo tanto como $S_k^+, \ S_k^-$ convergen entonces $u_k = u_0 + S_k^+ + S_k^- $ converge. \qed
	
\end{proof}

\begin{proof}{[De \ref{prop: equivalencias convexidad fuerte}]}
	\begin{enumerate}
		\item {[$1 \Longleftrightarrow 2$]} Notemos que $g$ es convexa si y s\'olo si:
		
		\begin{equation*}
			\begin{array}{lrcl}
				& g(y) & \geq & g(x) + \nabla g(x) ^T (y-x) \\
				\Longleftrightarrow & f(y) - \frac{\mu}{2}\norm{y}^2 & \geq & f(x) - \frac{\mu}{2}\norm{x}^2 + \left(\nabla f(x) - \mu x \right)^T \left(y -x\right) \\
				\Longleftrightarrow & f(y) & \geq & f(x) + \nabla f(x)^T \left(y-x\right) - \mu \left(\frac{\norm{x}^2 - \norm{y}^2}{2} +  x^T \left(y-x\right)\right) \\
				\Longleftrightarrow & f(y) & \geq & f(x) + \nabla f(x)^T \left(y-x\right) + \frac{\mu}{2} \left(\norm{y}^2 + \norm{x}^2\right) - \mu x^T y \\
				\Longleftrightarrow & f(y) & \geq & f(x) + \nabla f(x)^T \left(y-x\right) + \frac{\mu}{2} \norm{y-x}^2
			\end{array}
		\end{equation*}
		
		\item {[$2 \Longleftrightarrow 3$]} Notemos que $g$ es convexa si y s\'olo si:
		
		\begin{equation*}
			\begin{array}{lrcl}
				& \left( \nabla g(x) - \nabla g(y) \right)^T \left(x-y\right) & \geq & 0 \\
				\Longleftrightarrow & \left(\nabla f(x) - \mu x - \left[\nabla f (y) - \mu y\right]\right)^T \left(x-y\right) & \geq & 0\\
				\Longleftrightarrow & \left(\nabla f(x) - \nabla f (y) - \mu \left[x - y\right]\right)^T\left(x-y\right) & \geq & 0 \\
				\Longleftrightarrow & \left(\nabla f(x) - \nabla f (y) \right)^T \left(x-y\right)  - \mu \left(x-y\right)^T \left(x-y\right) & \geq & 0 \\
				\Longleftrightarrow & \left(\nabla f(x) - \nabla f (y) \right)^T \left(x-y\right)  & \geq & \mu  \norm{x-y}^2
			\end{array}
		\end{equation*}
		
		\item {[$2 \Longleftrightarrow 4$]} Notemos que $g$ es convexa si y s\'olo si:
		
		\begin{equation*}
			\begin{array}{llll}
				& g \left(\alpha x + (1-\alpha)y\right) & \leq & \alpha g(x) + (1-\alpha)g(y) \\
				\Longleftrightarrow & f\left(\alpha x + (1-\alpha)y\right) & \leq &  \frac{\mu}{2} \norm{\alpha x + (1-\alpha)y}^2 + \alpha \left(f(x) - \frac{\mu}{2} \norm{x}^2\right) + \\ &&& \left(1-\alpha\right) \left(f(y) - \frac{\mu}{2} \norm{y}^2\right) \\
				\Longleftrightarrow & f\left(\alpha x + (1-\alpha)y\right) & \leq & \left[\alpha f(x) + \left(1 - \alpha\right)f(y) \right] \\ &&& + \frac{\mu}{2} \left(\norm{\alpha x + (1-\alpha)y}^2 \right. \\ &&&  \left. - \left\lbrace \alpha\norm{x}^2 + (1-\alpha) \norm{y}^2 \right\rbrace \right) \\
				\Longleftrightarrow & f\left(\alpha x + (1-\alpha)y\right) & \leq & \alpha f(x) + \left(1 - \alpha\right)f(y) - \dfrac{\alpha (1-\alpha) \mu}{2} \norm{y-x}^2
			\end{array}
		\end{equation*}
		\qed
	\end{enumerate}
\end{proof}

\begin{proof}{[De \ref{prop: implicancias de convexidad fuerte}]}
	\begin{enumerate}
		\item Dado $x \in \R^d$ sea:
		
		\begin{equation*}
		q(z) = f(x) + \nabla f(x)^T (z-w) + \frac{1}{2} \mu \norm{z-x}_2^2
		\end{equation*}
		
		Se puede verificar que $z_* := x - \frac{1}{\mu} \nabla f(x)$ cumple que $q(z_*) = f(x) - \frac{1}{2\mu} \norm{\nabla f(x)}_2^2 \leq q(z)$ para todo $z \in \R^d$; luego por \ref{def: Fuertemente convexa} se tiene:
		
		\begin{equation*}
		f_{inf} \geq f(x) + \nabla f(x)^T (w_*-x) + \frac{1}{2} \mu \norm{w_*-x}_2^2 \geq f(x) - \frac{1}{2\mu} \norm{\nabla f(x)}_2^2 
		\end{equation*}
		
		\item Por Cauchy-Schwartz y usando \ref{prop: equivalencias convexidad fuerte}:
		
		\begin{equation*}
			\norm{\nabla f(x) - \nabla f(y)} \norm{x-y} \geq \left(\nabla f(x) - \nabla f(y)\right)^T \left(x-y\right) \geq \mu \norm{x-y}^2
		\end{equation*}
		
		\item Consideremos $\phi_x(z) = f(z) - \nabla f(x)^T z$, luego notemos que es $\mu-$fuertemente convexa; en efecto:
		
		\begin{equation*}
			\left(\nabla \phi_x(z_1) - \nabla \phi_x(z_2)\right)^T \left(z_1 - z_2\right) = \left(\nabla f(z_1) - \nabla f(z_2)\right)^T \left(z_1 - z_2\right) \geq \mu \norm{z_1 - z_2}^2
		\end{equation*}
		
		Luego si aplicamos la desigualdad PL a $\phi_x(z)$ evaluada en $z^* = x$ entonces:
		
		\begin{equation*}
			\begin{array}{rcl}
			\left(f(y) - \nabla f(x)^T y\right) - \left(f(x) - \nabla f(x)^T x\right) & = &  \phi_x(y) - \phi_x(x)\\
			& \leq  & \frac{1}{2 \mu} \norm{\nabla \phi_x(y)}^2 \\
			& = & \frac{1}{2 \mu} \norm{\nabla f(y) - \nabla f(x)}^2 
			\end{array}
		\end{equation*}
		
		\item Notemos que por el punto anterior:
		
		\begin{equation*}
			\begin{aligned}
				f(y) \leq f(x) + \nabla f(x)^T \left(y-x\right) + \frac{1}{2\mu} \norm{\nabla f(y) - \nabla f(x)}^2 \\
				f(x) \leq f(y) + \nabla f(y)^T \left(x-y\right) + \frac{1}{2\mu} \norm{\nabla f(x) - \nabla f(y)}^2 
			\end{aligned}
		\end{equation*}
		
		Luego si las sumamos y reordenamos:
		
		\begin{equation*}
			\left(\nabla f(x) - \nabla f(y)\right)^T \left(x-y\right) \leq \frac{1}{\mu} \norm{\nabla f(x) - \nabla f(y)}^2 
		\end{equation*}
		
	\end{enumerate}\qed
\end{proof}

\begin{proof}{[De \ref{prop: Implicancias L Lipschitz}]}
	\begin{enumerate}
		\item {[$2 \Longleftrightarrow 3$]} Notemos que $g$ es convexa si y s\'olo si:
		
		\begin{equation*}
		\begin{array}{lrcl}
		& g(y) & \geq & g(x) + \nabla g(x) ^T (y-x) \\
		\Longleftrightarrow & \frac{L}{2}\norm{y}^2 -  f(y)  & \geq & \frac{L}{2}\norm{x}^2 -  f(x) + \left(Lx - \nabla f(x)\right)^T \left(y-x\right) \\
		\Longleftrightarrow & \frac{L}{2}\norm{y}^2 -  f(y)  & \geq & \frac{L}{2}\norm{x}^2 -  f(x) + Lx^Ty - L\norm{x}^2 - \nabla f(x)^T \left(y-x\right) \\
		\Longleftrightarrow &f(y)   & \leq & f(x) + \nabla f(x)^T \left(y-x\right) + \frac{L}{2}\left(\norm{y}^2 + \norm{x}^2 -2 x^Ty\right)\\
		\Longleftrightarrow &f(y)   & \leq & f(x) + \nabla f(x)^T \left(y-x\right) + \frac{L}{2}\norm{y-x}^2\\
		\end{array}
		\end{equation*}
		
		\item {[$2 \Longleftrightarrow 4$]} Sale igual que $2 \Longleftrightarrow 3$ de \ref{prop: equivalencias convexidad fuerte}
		
		\item {[$2 \Longleftrightarrow 5$]} Sale igual que $2 \Longleftrightarrow 4$ de \ref{prop: equivalencias convexidad fuerte}
		
		\item {[$1 \Longrightarrow 4$]} 
		
		\begin{equation*}
		\left(\nabla f(x) - \nabla f(y)\right)^T \left(x-y\right) \leq \norm{\nabla f(x) - \nabla f(y)}\norm{x-y} \leq L \norm{x-y}^2 
		\end{equation*}
		
		\item {[$7 \Longrightarrow 1$]} 
		
		\begin{equation*}
		\begin{aligned}
		\norm{\nabla f(x) - \nabla f(y)}^2 & \leq & L \left(\nabla f(x) - \nabla f(y)\right)^T \left(x-y\right) \\ & \leq & L\norm{\nabla f(x) - \nabla f(y)}\norm{x-y}
		\end{aligned}
		\end{equation*} 
		
		\item {[$8 \Longrightarrow 6$]} Notemos que si cambiamos de lugar $x,y$ en $8$ entonces:
		
		
		\begin{equation*}
		\begin{array}{rcl}
			f(y) & \geq & f(x) + \dfrac{f\left(x + \alpha (y-x)\right) -f(x)}{\alpha} + \dfrac{1-\alpha}{2L}\norm{\nabla f(x) - \nabla f(y)}^2 \\
			\downarrow & \alpha \rightarrow 0 & \downarrow \\
			f(y) & \geq & f(x) + \nabla f(x)^T \left(y-x\right) +  \dfrac{1}{2L}\norm{\nabla f(x) - \nabla f(y)}^2 
		\end{array}
		\end{equation*} 
		
		\item {[$6 \Longrightarrow 8$]} Sea $z = \alpha x + (1-\alpha)y$, luego:
		
		\begin{equation*}
		\begin{aligned}
		f(y) & \geq & f(z) + \nabla f(z)^T \left(y-z\right) +  \dfrac{1}{2L}\norm{\nabla f(z) - \nabla f(y)}^2  \\
		f(x) & \geq & f(z) + \nabla f(z)^T \left(x-z\right) +  \dfrac{1}{2L}\norm{\nabla f(z) - \nabla f(x)}^2 
		\end{aligned}
		\end{equation*}
		
		Luego si multiplicamos la primera por $\alpha$, la segunda por $1-\alpha$ y las sumamos tenemos:
		
		\begin{equation*}
			\begin{aligned}
				f(\alpha x + (1-\alpha)y) & \leq & \alpha f(x) + (1-\alpha)f(y) - \dfrac{\alpha}{2L}\norm{\nabla f(z) - \nabla f(y)}^2 \\ & & - \dfrac{1-\alpha}{2L}\norm{\nabla f(z) - \nabla f(x)}^2 \\
				& \leq & \alpha f(x) + (1-\alpha)f(y) - \dfrac{\alpha (1-\alpha)}{2L}\norm{\nabla f(y) - \nabla f(x)}^2
			\end{aligned}
		\end{equation*}
		
		Pues $\norm{x-y}^2\alpha (1-\alpha) \leq \alpha \norm{x}^2 + (1-\alpha)\norm{y}^2$
		
			\item {[$2 \Longrightarrow 6$]} Si $f$ es convexa entonces consideremos $\phi_x(z) = f(z) - \nabla f(x)^T z$ que es m\'inimo en $z^* = x$ pues $f$ es convexa. Adem\'as por hip\'otesis $h(z) = \dfrac{L}{2} \norm{z}^2 - \phi_x(z)$ es convexa por lo que:
		
		\begin{equation*}
			\min\limits_{z \in \R^d} {\phi_x(z)} \leq \min\limits_{z \in \R^d} \sett{\phi_x(y) + \nabla \phi_x(y)^T \left(z-y\right) + \dfrac{L}{2}\norm{z-y}^2}
		\end{equation*}
		
		Luego reordenando:
		
		\begin{equation*}
		\begin{aligned}
			f(y) - f(x) - \nabla f(x)^T \left(y-x\right) & = & \phi_x(y) - \phi_x(x) \\
			& \geq & \frac{1}{2L} \norm{\nabla \phi_x(y)}^2 \\
			& = & \frac{1}{2L} \norm{\nabla f(y) - \nabla f(x)}^2
		\end{aligned}
		\end{equation*}
		\qed
	\end{enumerate}
\end{proof}

\begin{proof}{[De \ref{lemma1 : DC los puntos silla estrictos son fijos inestables}]}
	Manteniendo la notaci\'on previa a la afirmaci\'on:
	
	\begin{equation*}
	\begin{aligned}
	z_{i+1}^THz_{i+1} & \leq & \left[z_i^T - \alpha \Bigsum{j \in S_i}{\left( e_j^T H z_i \right) e_j^T} \right]H \left[ z_i - \alpha \Bigsum{j \in S_i}{\left(e_j^T H z_i \right) e_j }\right] \\
	& = & z_i^T H z_i - \alpha \Bigsum{j \in S_i}{\left(z_i^T H e_j\right)\left(e_j^T H z_i\right)} - \alpha \Bigsum{j \in S_i}{\left(e_j^T H z_i\right)\left(e_j^T H z_i\right)} \\
	&& + \alpha^2 \parenthesis{\Bigsum{j \in S_i}{\left(e_j^T H z_i\right)e_j}}^TH\parenthesis{\Bigsum{j \in S_i}{\left(e_j^T H z_i\right)e_j}} \\
	\parenthesis{\norm{H_{S_i}}_2 \leq L_b} & < & z_i^T H z_i -  2\alpha \Bigsum{j \in S_i}{\left(e_j^T H z_i\right)^2 } + \alpha ^2 L_b \norm{\Bigsum{j \in S_i}{\parenthesis{e_j^T H z_i}e_j}}^2_2 \\
	& = & z_i^T H z_i -  \alpha \parenthesis{2 - \alpha L_b}\norm{\Bigsum{j \in S_i}{\parenthesis{e_j^T H z_i}e_j}}^2_2 \\
	\parenthesis{\alpha L_b < 1} & < & z_i^T H z_i -  \alpha \norm{\Bigsum{j \in S_i}{\parenthesis{e_j^T H z_i}e_j}}^2_2 
	\end{aligned} 
	\end{equation*}
	
	Luego juntando todo probamos que $z_i^T H z_i$ es decreciente y cumple la cota:
	
	\begin{equation}
	\label{eq_2: DC los puntos silla estrictos son fijos inestables}
	z_{i+1}^THz_{i+1}  < z_i^T H z_i -  \alpha \norm{\Bigsum{j \in S_i}{\parenthesis{e_j^T H z_i}e_j}}^2_2 
	\end{equation}
	
	Por otro lado sabemos que para todo $w$ vale:
	
	\begin{equation}
	\label{eq_3: DC los puntos silla estrictos son fijos inestables}
	w^THw  \geq  \lambda_{min}(H) \norm{w}_2^2 \geq -L_b \norm{w}^2_2
	\end{equation}
	
	Luego si usamos \ref{claim1: DC los puntos silla estrictos son fijos inestables}, \ref{eq_3: DC los puntos silla estrictos son fijos inestables} y Cauchy-Schwartz existe $i \in \sett{1, \dots, b}$ y $\delta >0$ tal que:
	
	\begin{equation*}
	\begin{aligned}
	z_{i+1}^THz_{i+1} & < & z_i^T H z_i -  \alpha \Bigsum{j \in S_i}{\parenthesis{e_j^T H z_i}^2} \\
	& < &  z_i^T H z_i -  \frac{\alpha}{d} \parenthesis{\Bigsum{j \in S_i}{\abs{e_j^T H z_i}}}^2 \\
	& < &  z_i^T H z_i -  \dfrac{\delta^2}{d\alpha} \norm{z_i}_2^2\\
	& < &  \parenthesis{1 +  \dfrac{\delta^2}{d\alpha L_b}}z_i^T H z_i
	\end{aligned}
	\end{equation*}
	
	Tomando $\epsilon = \dfrac{\delta^2}{d\alpha L_b}$ probamos que $y_{t+1}^THy_{t+1} \leq (1+\epsilon) y_{t}^THy_{t} $ para $y_t \in Ran(H)$.
	
	Si $y_t = y_N + y_R$ con $y_N \in Ker(H)$, $y_R \in Ran(H)$ entonces $y_{t}^THy_{t} = y_{R}^THy_{R}$ y $y_{t+1} = Jy_t = y_N + Jy_R$ por lo que $y_{t+1}^THy_{t+1} = \parenthesis{Jy_{R}}^TH\parenthesis{Jy_{R}}$. Conclu\'imos:
	
	\begin{equation*}
	y_{t+1}^THy_{t+1} = \parenthesis{Jy_{R}}^TH\parenthesis{Jy_{R}} \leq (1+\epsilon) y_{R}^THy_{R} = (1+\epsilon) y_{t}^THy_{t}
	\end{equation*}
	\qed
\end{proof}

\begin{proof}{[De \ref{lemma: GD toma tiempo exponencial}]}
	
	Primero construyamos $g_1$. Sea $i \in \sett{1, \dots, d}$, luego si $x_i = \tau$ entonces $\dfrac{\partial f_{i,1}}{\partial x_i} = -2\gamma\tau$, $\dfrac{\partial^2 f_{i,1}}{\partial x_i^2} = -2\gamma$; mientras que si $x_i = 2\tau$ entonces $\dfrac{\partial f_{i+1,1}}{\partial x_i} = -4L\tau$ y $\dfrac{\partial^2 f_{i+1,1}}{\partial x_i^2} = 2L$. Como sabemos que $L > \gamma, 0 > -2\gamma\tau > -4L\tau$ y $2L > \dfrac{-4L\tau - \left(-2\gamma \tau\right)}{\tau}$ entonces por \ref{theorem: splines 1} existe $p(x_i) \in \R_3[x]$ tal que:
	
	\begin{equation*}
		\begin{aligned}
			p(\tau) & = & -2\gamma \tau \\
			p(2\tau) & = & -4L\tau \\
			p'(\tau) & = & -2\gamma \\
			p'(2\tau) & = & 2L \\
			p \vert_{\left[\tau, 2\tau\right]} & \leq & -2 \gamma \tau
		\end{aligned}
	\end{equation*}
	
	Definamos entonces:
	
	\begin{equation*}
	\begin{array}{ll}
		g_1(x_i) = & \left(\int p\right) (x_i) - \left(\int p\right) (\tau) - \gamma \tau^2 \\
		\eta = & - g_1(2\tau) + 4L \tau^2 \\
		g_2(x_i) = & -\gamma - \dfrac{10 (l+\gamma) \left(x_i - 2\tau\right)^3}{\tau^3} \\ & - \dfrac{15 (L+\gamma)\left(x_i - 2\tau\right)^4}{\tau^4} - \dfrac{6 (L+\gamma)\left(x_i - 2\tau\right)^5}{\tau^5}
	\end{array}
	\end{equation*}
	
	Luego notemos que $g_1, \eta$ cumplen las condiciones de borde para $x_i$ autom\'aticamente; por otro lado si consideramos $x_{i+1}$ notemos que:
	
	\begin{equation*}
		g_2' (x_i) = - \dfrac{30 \left(L+\gamma\right)\left(x_i - 2\tau\right)^2 \left(x_i - \tau\right)^2}{\tau^5}
	\end{equation*}
	
	Luego:
	
	\begin{equation*}
		\begin{aligned}
			g_2 \vert_{\left[\tau, 2\tau\right]} & \geq & -\gamma \\
			g_2' \vert_{\left[\tau, 2\tau\right]} & \leq & 0 \\
			g_2(\tau) & = & L\\
			g_2(2\tau) & = & -\gamma\\
			g_2'(\tau) & = & 0 \\
			g_2'(2\tau) & = & 0 \\
			g_2''(\tau) & = & 0 \\
			g_2''(2\tau) & = & 0 \\
		\end{aligned}
	\end{equation*}
	
	Luego $g_2$ cumple las condiciones de contorno en $x_{i+1}$ y adem\'as al tener derivadas cero en los l\'imites no contribuye a las condiciones de $x_i$. Conclu\'imos que con estas definiciones $g$ cumple lo pedido .\qed
\end{proof}

