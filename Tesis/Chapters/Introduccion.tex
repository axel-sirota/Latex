\chapter{Introducci\'on}\label{ch:introduccion}

\epigraph{Las Matem\'aticas no conocen de razas ni fronteras geogr\'aficas; para las Matem\'aticas el mundo cultural es un solo pa\'is.}{David Hilbert}

Machine Learning es un conglomerado de t\'ecnicas estad\'isticas, probabil\'isticas y algor\'itmicas para resolver el problema universal siguiente:

\begin{center}
\textbf{Dado un set de datos ya ocurridos, construir un algoritmo que aprenda los patrones intr\'insecos para poder predecir datos futuros bajo la misma distribuci\'on.}
\end{center}

Esto est\'a contextualizado en la formalizaci\'on matem\'atica del problema y la identificaci\'on de una familia rica de funciones que aproximen a este, lo que conlleva a un problema de optimizaci\'on convexa o no convexa seg\'un el caso. En este Tesis nos centramos en el an\'alisis de convergencia de algoritmos de optimizaci\'on que suelen aparecer en machine learning, los cuales se dividen en \textit{batch} o \textit{estoc\'asticos} dependiendo la naturaleza de \'este.

Dentro del espectro de los algoritmos de batch se encuentra el algoritmo de descenso m\'as pronunciado -tambi\'en conocido como gradiente, descenso de gradiente por batch o m\'etodo de gradiente completo- (GD) que se define en el algoritmo \ref{algo: GD - intro} y sus variantes que veremos en el cap\'itulo \ref{ch: aplicaciones}.

\RestyleAlgo{boxruled}
\LinesNumbered
\begin{algorithm}[H]
	\caption{Descenso de gradiente en batch \label{algo: GD - intro}}
	\textbf{Input:} $F: \R^d \rightarrow \R$, $F \in C^1$, $\alpha_k >0$, $w_1 \in \R^d$, $X = \sett{(x_j,y_j)}_{j \leq N} = \sett{\upxi_j}_{j \leq N}$ \text{ muestra aleatoria i.i.d.} \\
	\For{$k \in \N$}{
		$w_{k+1} \gets w_{k} - \alpha_k \sum\limits_{j=1}^{N} \nabla F(\upxi_j, w_k)$
	}
\end{algorithm}

Donde $F$ es la funci\'on objetivo a optimizar, $\sett{\alpha_k}$ resultan los incrementos positivos, $w_1$ la condici\'on inicial y $X$ el set de datos conocidos. 

Por otro lado, en el espectro \textit{estoc\'astico} encontramos el algoritmo \textit{descenso estoc\'astico de gradiente generalizado} (DE) definido en \ref{algo: DE - intro}:

 \RestyleAlgo{boxruled}
 \LinesNumbered
 \begin{algorithm}[H]
 	\caption{Descenso Estocastico de Gradiente (DE) \label{algo: DE - intro}}
 	\textbf{Input:} $w_1 \in \R^d$, $(x_k, y_k) = \upxi_j$ dato muestreado al azar\\
 	\For{$k \in \N$}{
 		$w_{k+1} \gets w_k - \alpha_kg(w_k, (x_k, y_k))$
 	}
 \end{algorithm}

Donde $g : \R^d \times \left( \R^{d_x} \times \R^{d_y} \right) \rightarrow \R^d$ es un estimador del vector $\nabla F := \left(\dfrac{\partial F}{\partial x_1}, \dots, \dfrac{\partial F}{\partial x_n}\right)$, $\sett{\alpha_k}$ resultan los incrementos positivos, $w_1$ la condici\'on inicial y $(x_k, y_k)$ un dato nuevo a analizar. Una variante muy utilizada en machine learning resulta de tomar $g(w_k, \left(x_k, y_k\right)) := \nabla F(w_k, x_k, y_k)$, caso conocido como \textit{descenso estoc\'astico de gradiente} (SGD) propuesto por Robbins y Monro \cite{robbins:1951}. Cada iteraci\'on de este m\'etodo es, por lo tanto, muy barata, y solo incluye el c\'alculo del gradiente $\nabla f_{i_k} (w_k)$ correspondiente a una muestra. El m\'etodo es notable porque la secuencia de iteraci\'on no est\'a determinada \'unicamente por la funci\'on $F$, el punto de inicio $w_1$, y la secuencia de incrementos $\left\lbrace \alpha _k \right\rbrace $, como lo har\'ia en un algoritmo de optimizaci\'on determinista. Por el contrario, $\left\lbrace w_k \right\rbrace $ es un proceso estoc\'astico cuyo comportamiento est\'a determinado por la secuencia aleatoria $\left\lbrace x_k \right\rbrace $.

En pos de analizar su convergencia vemos a los algoritmos determin\'isticos v\'ia el sistema din\'amico que inducen, mientras que a los algoritmos estoc\'asticos via el proceso estoc\'astico que inducen.

Hist\'oricamente se intentaron realizar algoritmos que tengan heur\'isticas m\'as y m\'as complejas para poder memorizar todos los casos excepcionales que ocurren (un ejemplo de esto son los an\'alisis de fraude), pero se observ\'o tanto emp\'irica como experimentalmente que los mejores resultados se obtuvieron mediante t\'ecnicas de machine learning; obteniendo tanto mejor robustez como estabilidad de las soluciones. Estos resultados motivan la investigaci\'on tanto en convergencia como en desarrollo de mejores algoritmos para obtener soluciones mejores.

Esta Tesis esta organizada seg\'un la categorizaci\'on de algoritmos mencionada anteriormente.

La primer parte (\ref{pt:introduccion}) refiere a la motivaci\'on tanto matem\'atica, algoritmica y del \'area para analizar la convergencia de los algoritmos presentados, como a su vez los contenidos preliminares usados a lo largo del documento. Al final, en el cap\'itulo \ref{ch:resumen}, se incluye un resumen de los resultados vistos, pensando mayoritariamente  en el practicante del Machine Learning que quiere verificar r\'apidamente condiciones de convergencia para sus algoritmos.

La segunda parte (\ref{pt:algoritmosbatch}) trata exclusivamente los algoritmos de \textit{tipo batch}. En el Cap\'itulo \ref{ch:convergenciaPuntual} , utilizando la gran referencia \cite{nesterov:2004}, analizamos la convergencia puntual del descenso de gradiente con condiciones de convexidad d\'ebil y luego la convergencia \textit{lineal} con convexidad m\'as fuerte. Luego en el cap\'itulo \ref{ch:teorema-de-variedad-estable} nos basamos en \cite{lee:2017} para ver a estos algoritmos como discretizaciones de sistemas din\'amicos y gracias al teorema de la variedad estable conclu\'imos un m\'etodo pr\'actico para analizar la convergencia \textit{casi todo punto}. Esta forma de analizar los algoritmos es aplicada en el cap\'itulo \ref{ch: aplicaciones} con varias variantes usualmente usadas en el \'area. Finalmente en el cap\'itulo \ref{ch:resultadosNegativos} nos basamos en \cite{du:2017} para ver que aunque se tiene convergencia \textit{casi todo punto}, la compleijdad algor\'itmica del descenso de gradiente es exponencial.

Esto nos motiva a estudiar los algoritmos estoc\'asticos en la parte \ref{pt:algoritmosestocasticos}. En el cap\'itulo \ref{ch:convergenciaL1} nos basamos en \cite{bottou:2016} para analizar la convergencia en \textit{norma $L1$} al m\'inimo (o a un entorno de \'este). Mientras que en el cap\'itulo \ref{ch:convergenciaCTP}, utilizando \cite{bottou:1999}, estudiamos la convergencia \textit{casi todo punto} tanto en los casos convexo como no convexo; aprovechando que el algoritmo induce un proceso estoc\'astico que a su vez induce una \textit{cuasi-martingala} convergente. En general, en lugar de contrastar los DE y otros m\'etodos basados en los resultados de experimentos num\'ericos -que pueden sesgar nuestra revisi\'on hacia un conjunto de pruebas limitado y detalles de implementaci\'on- enfocamos nuestra atenci\'on en las compensaciones computacionales fundamentales y las propiedades te\'oricas de los m\'etodos de optimizaci\'on.