%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\pdfbookmark[1]{Abstract}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Resumen}

En esta tesis intentamos responder a la simple pregunta: 

\begin{center}
	\textbf{\textquestiondown Bajo qu\'e condiciones convergen los m\'etodos de primer orden m\'as utilizados en Machine Learning?} 
\end{center}

Para ello utilizamos herramientas de sistem\'as din\'amicos y procesos estoc\'asticos en pos de analizar la convergencia tanto en algoritmos determin\'isticos como estoc\'asticos. 

Notamos que aunque los algoritmos determin\'isticos gozan de una velocidad excepcional en el caso convexo, esto no se generaliza al caso no convexo donde la convergencia puede ser hasta de orden exponencial. Por otro lado, en el caso estoc\'astico la misma naturaleza de \'este garantiza una complejidad uniforme en ambos r\'egimenes, a\'un en el rango del \textit{big data}. Sumado a esto dimos motivos tanto te\'oricos como pr\'acticos para la preferencia de los algoritmos estoc\'asticos, relacionados a la velocidad de convergencia a entornos de la soluci\'on en el caso general.

\endgroup

\vfill
