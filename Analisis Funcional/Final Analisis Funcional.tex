\documentclass[11pt]{article}

\usepackage{amsfonts}
\usepackage{amsmath,accents,amsfonts, amssymb, mathrsfs }
\usepackage{tikz-cd}
\usepackage{graphicx}
\usepackage{syntonly}
\usepackage{color}
\usepackage{mathrsfs}
\usepackage[spanish]{babel}
\usepackage[latin1]{inputenc}
\usepackage{fancyhdr}
\usepackage[all]{xy}
\usepackage[at]{easylist}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=black,bookmarksopen=true]{hyperref}

\usepackage{bookmark}

\topmargin-2cm \oddsidemargin-1cm \evensidemargin-1cm \textwidth18cm
\textheight25cm


\newcommand{\B}{\mathcal{B}}
\newcommand{\Cont}{\mathcal{C}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\inte}{\mathrm{int}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\inc}{\hookrightarrow}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\R}{{\mathbb{R}}}
\newcommand{\N}{{\mathbb{N}}}
\newcommand\tq{~:~}
\newcommand{\x}[3]{#1_#2^#3}
\newcommand{\xx}[4]{#1_#3#2_#4}
\newcommand\dd{\,\mathrm{d}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\ip}[1]{\left\langle#1\right\rangle}
\renewcommand\tt{\mathbf{t}}
\newcommand\nn{\mathbf{n}}
\newcommand\bb{\mathbf{b}}                      % binormal
\newcommand\kk{\kappa}
\newcommand{\sett}[1]{\left\lbrace#1\right\rbrace}
\newcommand{\interior}[1]{\accentset{\smash{\raisebox{-0.12ex}{$\scriptstyle\circ$}}}{#1}\rule{0pt}{2.3ex}}
\fboxrule0.0001pt \fboxsep0pt
\newcommand{\Bigcup}[2]{\bigcup\limits_{#1}{#2}}
\newcommand{\Bigcap}[2]{\bigcap\limits_{#1}{#2}}
\newcommand{\Bigprod}[2]{\prod\limits_{#1}{#2}}
\newcommand{\Bigcoprod}[2]{\coprod\limits_{#1}{#2}}
\newcommand{\Bigsum}[2]{\sum\limits_{#1}{#2}}
\newcommand{\BigsumA}[3]{ \sideset{}{^#2}\sum\limits_{#1}{#3}}
\newcommand{\Biglim}[2]{\lim\limits_{#1}{#2}}
\newcommand{\quotient}[2]{{\raisebox{.2em}{$#1$}\left/\raisebox{-.2em}{$#2$}\right.}}

\def \le{\leqslant}	
\def \ge{\geqslant}
\def\noi{\noindent}
\def\sm{\smallskip}
\def\ms{\medskip}
\def\bs{\bigskip}
\def \be{\begin{enumerate}}
	\def \en{\end{enumerate}}
\def\deck{{\rm Deck}}
\def\Tau{{\rm T}}

\newtheorem{mytheorem}{Theorem}
 %

\newtheorem{theorem}{Teorema}
\numberwithin{theorem}{subsection}
\newtheorem{lemma}[theorem]{Lema}

\newtheorem{proposition}[theorem]{Proposici\'on}

\newtheorem{corollary}[theorem]{Corolario}


\newenvironment{proof}[1][Demostraci\'on]{\begin{trivlist}
		\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{definition}[1][Definici\'on]{\begin{trivlist}
		\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{example}[1][Ejemplo]{\begin{trivlist}
		\item[\hskip \labelsep {\bfseries #1 }]}{\end{trivlist}}
\newenvironment{remark}[1][Observaci\'on]{\begin{trivlist}
		\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{declaration}[1][Afirmaci\'on]{\begin{trivlist}
		\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}


\newcommand{\qed}{\nobreak \ifvmode \relax \else
	\ifdim\lastskip<1.5em \hskip-\lastskip
	\hskip1.5em plus0em minus0.5em \fi \nobreak
	\vrule height0.75em width0.5em depth0.25em\fi}

\newcommand{\twopartdef}[4]
{
	\left\{
	\begin{array}{ll}
		#1 & \mbox{ } #2 \\
		#3 & \mbox{ } #4
	\end{array}
	\right.
}

\newcommand{\threepartdef}[6]
{
	\left\{
	\begin{array}{lll}
		#1 & \mbox{ } #2 \\
		#3 & \mbox{ } #4 \\
		#5 & \mbox{ } #6
	\end{array}
	\right.
}

\tikzset{commutative diagrams/.cd,
	mysymbol/.style={start anchor=center,end anchor=center,draw=none}
}
\newcommand\Center[2]{%
	\arrow[mysymbol]{#2}[description]{#1}}

\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
		\node[shape=circle,draw,inner sep=2pt] (char) {#1};}}


\begin{document}
	
	\pagestyle{empty}
	\pagestyle{fancy}
	\fancyfoot[CO]{\slshape \thepage}
	\renewcommand{\headrulewidth}{0pt}
	
	
	
	\centerline{\bf An\'alisis Funcional - $1^{\circ}$ cuatrimestre $2017$}
	\centerline{\sc Final}
	
	\tableofcontents
	\bigskip

\section{Espacios Vectoriales}

\subsection{Propiedades Elementales}

\begin{definition}
Si $\mathcal{X}$ es un espacio vectorial sobre un cuerpo $\mathbb{F}$, un conjunto $\mathcal{B} = \sett{v_i}_{i \in I}$ se dice:

\begin{enumerate}
\item \textit{Linealmente independiente} si dados $v_{i_1}, \dots, v_{i_k} \in \B$ y $\lambda_{i_1},  \dots, \lambda_{i_k} \in \F$ tal que $\Bigsum{i}{\lambda_{i_i}v_{i_i}} = 0$ implica que $\lambda_{i_i} = 0$ para todo $1 \leq i \leq k$.
\item \textit{Sistema de generadores} si dado $v \in \mathcal{X}$ entonces existen $v_{i_1}, \dots, v_{i_k} \in \B$ y $\lambda_{i_1},  \dots, \lambda_{i_k} \in \F$ tal que $\Bigsum{i}{\lambda_{i_i}v_{i_i}} = v$.
\item \textit{Base} si es a la vez un sistema de generadores linealmente independiente.
\end{enumerate}
\end{definition}

\begin{example}



\begin{itemize}
	\item $X=\R[X]$ es un espacio vectorial, si consideramos $\B = \sett{1,X,X^2, \dots} = \sett{X^j}_{j \in \N}$ es base.
	\item $X=\mathcal{C}[a,b]$ es un espacio vectorial, si consideramos $\B = \sett{e^{\alpha x}, \alpha \in [0,1]}$ veamos que es linealmente independiente.
	
	\begin{proof}
		Sean $\alpha_1, \dots, \alpha_n \in [0,1]$ y $\lambda_{1}, \dots, \lambda_{n} \in \R$ tal que $\Bigsum{i}{\lambda_i e^{\alpha_i x}} = 0$ para todo $x \in [a,b]$; luego si derivamos $n-1$ veces tenemos el sistema:
		
		\[
			\left(
				\begin{array}{cccc}
					e^{\alpha_1 x} &  e^{\alpha_2 x} &  \dots &  e^{\alpha_n x} 
				\end{array}
			\right)
			\left(
				\begin{array}{cccc}
					1 & \alpha_1 &  \dots &  \alpha_1^{n-1} \\
					\vdots & \vdots & \vdots & \vdots \\
					1 &  \alpha_n &  \dots &  \alpha_n^{n-1}					 
				\end{array}
			\right)
			\left(
			\begin{array}{c}
			\lambda_{1} \\
			\lambda_{2} \\
			\vdots \\
			\lambda_{n}
			\end{array}
			\right) = 
			\left(
			\begin{array}{c}
			0 \\
			0 \\
			\vdots \\
			0
			\end{array}
			\right)
		\]
		Y como los $\alpha_i$ son distintos entonces la matriz de Vandermonde es inversible y el sistema admite una \'unica soluci\'on, $\lambda_{1} = \lambda_{2} = \dots = \lambda_{n} = 0$. \qed
	\end{proof}

\end{itemize}
\end{example}

Recordemos:

\begin{proposition}[Lema de Zorn]
	\label{Lema de Zorn}
	
	Si $(P,\leq)$ es un conjunto parcialmente ordenado, no vac\'io, tal que todo subconjunto no vac\'io $S \subseteq P$ totalmente ordenado admite una cota superior; entonces existe un elemento maximal en $P$.
\end{proposition}

\begin{proposition}
	Si $E$ es un espacio vectorial, entonces $E$ admite una base.
\end{proposition}

\begin{proof}
	Consideremos $P = \sett{S \subseteq E \ / \ S \text{ es li}}$ y dotemoslo del orden dado por la inclusi\'ion, luego $P \neq \emptyset$ pues si $v \in E$ entonces $\sett{v} \in P$.
	
	Sea $\sett{S_i}$ una colecci\'on de subconjuntos de $P$ totalmente ordenada y sea $T = \Bigcup{i \in I}{S_i}$, luego es claro que $S_i \leq T$; faltar\'ia ver que $T \in P$.
	
	Para eso sean $v_{i_1}, \dots, v_{i_k} \in T$ y $\lambda_{i_1},  \dots, \lambda_{i_k} \ in \F$ tales que $\Bigsum{k}{\lambda_i v_i} = 0$. Como son finitos existe $k_0 \in \N$ tal que $v_i \in S_{k_0}$ para todo $i$, que al ser un conjunto linealmente independiente resulta que $\lambda_{1} = \lambda_{2} = \dots = \lambda_{n} = 0$. Conclu\'imos que $T \in P$, luego por \ref{Lema de Zorn} existe $M \in P$ elemento maximal.
	
	Finalmente, sea $v \in E \setminus <M>$ (el conjunto generado por combinaciones lineales de $M$), luego $M \cup \sett{v}$ ser\'ia un conjunto li lo que contradice la maximalidad de $M$; por ende no existe tal $v$ y $M$ resulta base. \qed
	
	
	
\end{proof}

\begin{proposition}
	\label{Dos bases tienen mismo cardinal, Hamel}
	Sea $E$ un espacio vectorial y sean $\B_1, \B_2$ dos bases de Hamel de $E$. Luego $\#B_1 = \#B_2$.
\end{proposition}

\begin{proof}
	Sea $x \in \B_1$ y llamemos $S(x)$ al conjunto de los elementos $v \in \B_2$ tal que al escribir a $x$ como combinaci\'on lineal de elementos de $\B_2$ aparece $v$, por lo que si $x = \Bigsum{k}{\lambda_{i_k} v_{i_k}}$ entonces $S(x) = \sett{v_{i_1}, \dots, v_{i_n}}$.
			
	\begin{lemma}
		\label{Lema de cardinalidad de bases}
		$\Bigcup{x \in \B_1}{S(x)} = \B_2$
	\end{lemma}
	\begin{proof}{Del lema}
		Si $v \in \Bigcup{x \in \B_1}{S(x)}$ luego existe $x_0 \in \B_1$ tal que $v \in S(x_0)$ por lo que $v \in \B_2$ por definici\'on de $S(x)$. Rec\'iprocamente, si $v \in \B_2$ pero no existe $x \in \B_1$ tal que $v \in S(x)$, entonces $v \not \in <\B_1> =E = <\B_2>$. \qed
	\end{proof}
	
	Por \ref{Lema de cardinalidad de bases} tenemos que $\# \B_2 \leq \Bigsum{x \in \B_1}{\#S(x)} \leq \#\N \#\B_1 \leq \#B_1$.
	
	Razonando al rev\'es obtenemos la otra desigualdad. \qed		
	
\end{proof}

\subsection{Normas y productos internos}

\begin{definition}
	Si $E$ es un espacio vectorial, una norma definida en $E$ es una aplicaci\'on $\norm{.}: E \mapsto \R$ tal que:
	
	\begin{enumerate}
		\item $\norm{x} \geq 0$
		\item $\norm{x} = 0 \ \Longleftrightarrow x = 0$
		\item $\norm{\lambda x} = \abs{\lambda} \norm{x} $
		\item $\norm{x+y} \leq \norm{x} + \norm{y}$
	\end{enumerate}
	
\end{definition}

\begin{remark}
	Todo espacio normado es un espacio m\'etrico pero no viceversa.
\end{remark}

\begin{definition}
	Si $E$ es un espacio vectorial, un producto interno definido en $E$ es una aplicaci\'on $\ip{.,.}: E \times E \mapsto F$ tal que:
	
	\begin{enumerate}
		\item $\ip{.,z}$ es lineal
		\item $\ip{x,x} = 0 \ \Longleftrightarrow x = 0$
		\item $\ip{x,y} = \overline{\ip{y,x}}$
	\end{enumerate}
	
\end{definition}


\begin{remark}
	Todo espacio con producto interno es un espacio normado pero no viceversa.
\end{remark}

\begin{theorem}[Cauchy-Schwartz]
	\label{Desigualdad de Cauchy-Schwartz }
	Sea $E$ un espacio vectorial y $\ip{.}$ un producto interno definido en $E$; luego si $x,y \in E$ se tiene que $\abs{\ip{x,y}} \leq \norm{x} \norm{y}$.
\end{theorem}

\begin{proof}
	Sean $x,y \in E$, $\lambda \in \C$ y sea $z = x-\lambda y$, luego $\ip{z,z} = \ip{x,x} + \abs{\lambda^2}\ip{y,y} -2 \Re(\lambda \ip{y,x}) \geq 0$.
	
	Si $\ip{y,x} = re^{i \theta}$ sea $\lambda = e^{-i \theta}t$ con $t \in \R$; luego:
	
	\[
		0 \geq \ip{x,x} + t^2 \ip{y,y} - 2bt \equiv c -2bt + at^2 := q(t)
	\]
	
	Luego como la cuadr\'atica dada es positiva, eso implica que $0 \leq 4b^2 -4ac$ por lo que:
	
	\[
		0 \leq b^2 -ac = \abs{\ip{x,y}}^2 - \ip{x,x}\ip{y,y}
	\]
	
	Si $\abs{\ip{x,y}}= \norm{x} \norm{y}$, entonces $b^2 = \ip{x,x} \ip{y,y}$ por lo que $b^2 -ac = 0$. Esto implica que existe $t_0$ tal que $q(t_0) = 0$, por lo tanto eso implica que $\ip{x-e^{-i \theta}t_0 y,x- e^{-i \theta}t_0 y} \equiv 0$ y por lo tanto $x = e^{-i \theta}t_0 y$. \qed
	
\end{proof}

\begin{definition}
	Un espacio normado que es completo respecto a la distancia inducida por la norma se llama \textit{Espacio de Banach}
\end{definition}

\begin{definition}
	Un \textit{Espacio de Hilbert} es un espacio de Banach donde la norma proviene de un producto interno mediante $\norm{x} = \sqrt{\ip{x,x}}$.
\end{definition}

\begin{proposition}
	\label{Identidad de poralizacion}
	Sea $E$ un espacio con producto interno, entonces:
	
	\begin{itemize}
		\item $\mathcal{R}(\ip{x,y}) = \frac{1}{4}\left(\norm{x+y}^2 - \norm{x-y}^2\right)$
		\item $\mathcal{I}(\ip{x,y}) = \frac{1}{4}\left(\norm{x+iy}^2 - \norm{x-iy}^2\right)$
	\end{itemize}

\end{proposition}

\begin{proof}
	Por un lado $\norm{x+y}^2 = \norm{x}^2 + \norm{y}^2 + 2\mathcal{R}(\ip{x,y})$ y $\norm{x-y}^2 = \norm{x}^2 + \norm{y}^2 - 2\mathcal{R}(\ip{x,y})$; por lo que restando se obtiene:
	
	\[
		4\mathcal{R}(\ip{x,y}) = \norm{x+y}^2 - \norm{x-y}^2
	\]
	
	Por el otro: 
	
	\[
	\begin{aligned}
		\norm{x+iy}^2 = & \ip{x+iy,x+iy} \\
					  = & \norm{x}^2 + \abs{i}\norm{y}^2 -i \ip{x,y} + i \overline{\ip{x,y}} \\
					  = & \norm{x}^2 + \norm{y}^2 -i 2 \mathcal{I}(\ip{x,y}) \\
		\norm{x-iy}^2 = & \ip{x-iy,x-iy} \\
			   		  = & \norm{x}^2 + \abs{i}\norm{y}^2 +i \ip{x,y} - i \overline{\ip{x,y}} \\
					  = & \norm{x}^2 + \norm{y}^2 +i 2 \mathcal{I}(\ip{x,y}) \\
	\end{aligned}
	\]
	
	Por lo tanto restando ambas obtenemos:
	
	\[
		4\mathcal{I}(\ip{x,y}) = \norm{x+iy}^2 - \norm{x-iy}^2
	\]
	\qed
	
\end{proof}

\begin{proposition}[Ley del paralelogramo]
	\label{Ley del paralelogramo}
	Sea $E$ un espacio normado real, entonces existe $\ip{.,.}: E \times E \rightarrow \C$ tal que $\norm{x}= \sqrt{\ip{x,x}}$ si y s\'olo si para todos $x,y \in E$ vale:
	
	\[
		\norm{x+y}^2 + \norm{x-y}^2 = 2\norm{x}^2 + 2\norm{y}^2
	\]
\end{proposition}

\begin{proof}
	Si $\norm{x} = \sqrt{\ip{x,x}}$ entonces de la demostraci\'on de \ref{Identidad de poralizacion} se da el resultado. Rec\'iprocamente definamos:
	
	 $$ \ip{x,y} := \frac{1}{4}\left(\norm{x+y}^2 - \norm{x-y}^2\right)$$
	
	Luego verifiquemos que es un producto interno.
	
	\begin{enumerate}
		\item $\sqrt{\ip{x,x}} = \norm{x}$
		\item Como $\norm{x+y} = \norm{y+x}$ y $\norm{x-y} = \norm{-(y-x)} = \norm{y-x}$ conclu\'imos que $\ip{x,y} = \ip{y,x}$.
		\item Dado que $\norm{.}, +, -, *$ son $\norm{.}$-continuas entonces $\ip{.,x},\ip{x,.}$ es $\norm{.}$-continua.
		\item Sean $x,y,z \in E$ entonces:
		
		\[
		\begin{aligned}
			\norm{x+y+z}^2 = & 2\norm{x+z}^2 + 2\norm{y}^2 - \norm{x-y+z}^2
						   = & 2\norm{y+z}^2 + 2\norm{x}^2 - \norm{y - x+z}^2
		\end{aligned}
		\]
		
		Luego como $A=B$ y $A=C$ implica $A=\frac{B+C}{2}$ se obtiene:
		
		\[
		\begin{aligned}
			\norm{x+y+z}^2 = & \norm{x+z}^2 + \norm{y}^2 - \frac{1}{2}\norm{x-y+z}^2 + \norm{y+z}^2 + \norm{x}^2 - \frac{1}{2}\norm{y - x+z}^2 \\
			\norm{x+y-z}^2 = & \norm{x-z}^2 + \norm{y}^2 - \frac{1}{2}\norm{x-y-z}^2 + \norm{y-z}^2 + \norm{x}^2 - \frac{1}{2}\norm{y - x-z}^2 \\
						   = & \norm{x-z}^2 + \norm{y}^2 - \frac{1}{2}\norm{-x+y+z}^2 + \norm{y-z}^2 + \norm{x}^2 - \frac{1}{2}\norm{-y + x+z}^2 
		\end{aligned}
		\]
		
		Por lo tanto:
		
		\[
			\begin{aligned}
				\ip{x+y,z} = & \frac{1}{4} \left(\norm{x+y+z}^2 - \norm{x+y-z}^2\right) \\
						   = & \frac{1}{4} \left(\norm{x+z}^2 - \norm{x-z}^2\right) + \frac{1}{4} \left(\norm{y+z}^2 - \norm{y-z}^2\right) \\
						   = & \ip{x,z} + \ip{y,z}
			\end{aligned}
		\]
		
		\item Por el item anterior es claro por inducci\'on que $\lambda \ip{x,y} = \ip{\lambda x,y}$ para todo $\lambda \in \N$ y como vale para $\lambda = -1$ tenemos que vale para todo $\lambda \in \Z$. Si $\lambda = \frac{p}{q} \in \Q$ entonces si llamamos $x' = \frac{x}{q}$ tenemos:
		
		\[
			q\ip{\lambda x, y} = q \ip{p x',y} = p \ip{qx',y} = p \ip{x,y}
		\]
		
		Luego $\lambda \ip{x,y} = \ip{\lambda x, y}$ para todo $\lambda \in \Q$. Por lo tanto probamos que fijados $x,y \in E$ la funci\'on $g(t)=\frac{1}{t} \ip{tx,y}$ y la funci\'on constante $h(t) = \ip{x,y}$ cumplen que $h\vert_{\Q} = g \vert_{\Q}$ y por continuidad entonces $h \equiv g$ para todo $t \in \R \setminus \sett{0}$; como el caso $\lambda = 0$ es trivial conclu\'imos que $\lambda \ip{x,y} = \ip{\lambda x,y}$. \qed
		
	\end{enumerate}
	
\end{proof}

\section{Espacios de Hilbert}

\subsection{Preliminares}

\begin{proposition}
	\label{Prod interno es continuo}
	Sea $E$ un espacio vectorial con producto interno, luego el producto interno es continuo.
\end{proposition}

\begin{proof}
	Sea $x_n, (y_n)$ tales que $x_n \rightarrow x, y_n \rightarrow y$, luego:
	
	\begin{equation*}
	\begin{aligned}
		\abs{\ip{x_n,y_n} -  \ip{x,y}} = & \abs{\ip{x_n - x,y_n} + \ip{x,y_n - y}} \\ 
		\leq & \abs{\ip{x_n-x,y_n}} + \abs{\ip{x,y_n-y}} \\
		\leq & \abs{\ip{x_n-x,y_n -y}} + \abs{\ip{x_n-x,y}} + \abs{\ip{x,y_n-y}} \\ 
		\leq & \norm{x_n - x}\norm{y} + \norm{x}\norm{y_n-y} + \norm{x_n - x}\norm{y_n-y} \rightarrow 0 
	\end{aligned}
	\end{equation*}
	\qed
\end{proof}

\subsection{Conjuntos ortogonales y ortonormales}

\begin{definition}
	Sea $E$ un espacio vectorial con producto interno, luego dados dos vectores $x,y \in E$ decimos que son \textit{ortogonales} si $\ip{x,y} = 0$.
	
	A su vez decimos que son \textit{ortonormales} si osn ortogonales y $\norm{x} = \norm{y} = 1$
	
	Finalmente dado un conjunto $S \subseteq E$ entonces decimos que es \textit{ortogonal / ortonormal} si dados cualesquiera $x,y \in S$ resulta que son \textit{ortogonales / ortonormales} 
\end{definition}

\begin{example}
	El conjunto $\sett{e^{inx} \ , \ n \in \N \ , \ x \in [0,2 \pi]}$ es ortonormal.
\end{example}

\begin{theorem}
	\label{Escritura de proyeccion a un conjunto ortonormal}
	Sea $E$ un espacio vectorial con producto interno y sea $S \subseteq E$ un conjunto ortonormal, luego si $x \in \ip{S}$ entonces existe una \'unica escritura de $x$ dada por:
	
	$$x = \sum\limits_{i = 1}^{n}{\ip{x,u_i}u_i} \qquad u_i \in S$$
	
\end{theorem}

\begin{proof}
	Como $x \in \ip{S}$ entonces existen \'unicos $\lambda_{1},\dots, \lambda_{n}$ tal que $x = \sum\limits_{i = 1}^{n}{\lambda_i u_i}$. Luego:
	
	
	\[
		\ip{x,u_j} = \sum\limits_{i = 1}^{n}{\lambda_i \ip{u_i,u_j}} = \lambda_j
	\]
	\qed
\end{proof}

\begin{theorem}[Desigualdad de Bessel]
	\label{Desigualdad de Bessel}
	Sea $E$ un espacio vectorial con producto interno y sea $S \subseteq E$ un conjunto ortonormal, luego:
	
	\begin{enumerate}
		\item SI $x \in E$ y $u_1, \dots, u_n \in S$ luego $\sum\limits_{i = 1}^{n}{\abs{\ip{x,u_i}}^2} \leq \norm{x}^2$
		\item Si $x \in E$ entonces $\sett{u \in S \ / \ \ip{x,u}\neq 0}$ es a lo sumo numerable
		\item Si $x,y \in E$ entonces $\abs{\Bigsum{u \in S}{\ip{x,u}\overline{\ip{y,u}}}} \leq \norm{x}\norm{y}$
	\end{enumerate}
\end{theorem}

\begin{proof}
	\begin{enumerate}
		\item Sean $u_1,\dots,u_n \in S$ y sea $z = x - \sum\limits_{i = 1}^{n}{{\ip{x,u_i}}}$, luego:
	
	\[
	\begin{aligned}
		0 \leq & \ip{z,z} \\
		= & \ip{x - \sum\limits_{i = 1}^{n}{\ip{x,u_i}},x - \sum\limits_{i = 1}^{n}{\ip{x,u_i}}} \\
		= & \norm{x}^2 + \norm{\sum\limits_{i = 1}^{n}{\ip{x,u_i}}}^2 - 2 \mathcal{R} \left(\ip{\sum\limits_{i = 1}^{n}{\ip{x,u_i}},x}\right) \\
		= & \norm{x}^2 + \sum\limits_{i = 1}^{n}{\norm{\ip{x,u_i}}^2} - 2 \mathcal{R} \left(\sum\limits_{i = 1}^{n}{\abs{\ip{x,u_i}}^2}\right) \\
		= & \norm{x}^2 - \sum\limits_{i = 1}^{n}{\norm{\ip{x,u_i}}^2}.
	\end{aligned}
	\]
	
	\item Notemos que $S = \sett{u \in S \ / \ \abs{\ip{x,u}} > 0} = \Bigcup{n \in \N}{\underbrace{\sett{u \in S \ / \ \abs{\ip{x,u}} \geq \frac{1}{m} }}_{T_m}}$.
	
	Ahora sean $u_1,\dots,u_n \in T$ por el item anterior sabemos que:
	
	\[
		\frac{n}{m^2} \leq \Bigsum{1 \leq k \leq n}{\abs{\ip{x,u_k}}^2} \leq \norm{x}^2
	\]
	
	Por lo que $n \leq m^2 \norm{x}^2$ y entonces $\# T_m \leq m^2 \norm{x}^2 < \infty$ para todo $m$, por lo tanto $\# S \leq \# \N * \# T_m \leq \# \N$.
	
	\item Sean $x,y \in E$ y $u_1,\dots,u_n \in S$, luego:
	\[
	 \begin{aligned}
	 	 \abs{\sum\limits_{i = 1}^{n}{\ip{x,u_i}\overline{\ip{y,u_i}}}} \leq_\text{C-S} & \sqrt{ \sum\limits_{i = 1}^{n}{\abs{\ip{x,u_i}}^2}}\sqrt{ \sum\limits_{i = 1}^{n}{\abs{\ip{y,u_i}}^2}} \\
	 	 \leq_\text{a} & \norm{x}\norm{y}
	 \end{aligned}
	\]
	\qed
	\end{enumerate}
\end{proof}

\begin{theorem}
	\label{Todo conjunto ortonormal en un separable es numerable}
	Si $E$ es un espacio vectorial con producto interno tal que $E$ es separable, entonces todo conjunto ortonormal es a lo sumo numerable
\end{theorem}

\begin{proof}
	Sea $S \subseteq E$ un conjunto ortonormal y sean $u \neq v \in S$, luego $\norm{u-v}^2 = \norm{u}^2 + \norm{v}^2 = 2$ y por lo tanto $B_{\frac{\sqrt{2}}{2}}(u) \cap B_{\frac{\sqrt{2}}{2}}(v) = \emptyset$.
	
	Sea $D \subseteq E$ un subconjunto denso numerable, luego $B_{\frac{\sqrt{2}}{2}}(u) \cap D \neq \emptyset$ para todo $u \in S$. Consideremos $f:S \rightarrow D$ dado por $f(u) \in B_{\frac{\sqrt{2}}{2}}(u) \cap D$, luego si $f(u) = f(v)$ entonces $f(v) \in B_{\frac{\sqrt{2}}{2}}(u) \cap B_{\frac{\sqrt{2}}{2}}(v) $ y por lo tanto $u = v$. Como $f$ es inyectiva conclu\'imos que $S$ es a lo sumo numerable. \qed
	
\end{proof}

\begin{theorem}
	\label{Proyeccion de un elemento en un ortonormal}
	Sean $H$ un espacio de Hilbert, $u_n$ una sucesi\'on de vectores ortonormales  y $c_n$ una sucesi\'on de numeros complejos. Luego:
	
	\begin{equation}
		\Bigsum{n \in \N}{c_nu_n} \in H \ \Longleftrightarrow \ \Bigsum{n \in \N}{\abs{c_n}^2} < \infty
	\end{equation}
	
	M\'as a\'un, $c_n = \ip{\Bigsum{n \in \N}{c_n u_n}, u_n}$
	
\end{theorem}

\begin{proof}
	Sea $S_k = \sum\limits_{i = 1}^{k}{c_i u_i}$, luego como $(u_n)$ son ortonormales dos a dos y $H$ es completo:
	
	\[
			\norm{\sum\limits_{i = k+ 1}^{k'}{c_n u_n}}^2 = \sum\limits_{i = k+ 1}^{k'}{\abs{c_n}^2}
	\]
	Por ende:
	\begin{equation*}
				\Bigsum{n \in \N}{c_nu_n} \in H \ \Longleftrightarrow \ \Bigsum{n \in \N}{\abs{c_n}^2} < \infty
	\end{equation*}
	
	Finalmente, notemos que $\ip{S_k,u_j} = c_j$ para todo $k \geq j$ y ,adem\'as si $(c_n) _in l^2$, entonces $S_k \rightarrow \Bigsum{n \in \N}{c_n u_n}=:x$; por lo tanto por \ref{Prod interno es continuo} $c_n = \ip{S_k,u_n} \rightarrow \ip{x,u_n}$. 
	\qed
	
\end{proof}

\begin{definition}
	Sea $E$ un espacio vectorial con producto interno y $M \subseteq E$, definimos \textit{el ortogonal a } $M$ como $M^{\perp} = \sett{x \in E \ / \ \ip{x,m} = 0 \ \forall m \in M}$.
\end{definition}

\begin{proposition}
	\label{El ortogonal es cerrado}
	$M^{\perp}$ es un subespacio cerrado de $E$
\end{proposition}

\begin{proof}
	Si $(x_n) \subset M$ es tal que $x_n \rightarrow x$ entonces por \ref{Prod interno es continuo} $0 = \ip{m,x_n} \rightarrow \ip{m,x}$, por lo que $x \in M$. \qed
\end{proof}

\begin{theorem}
	\label{Proyeccion a un conjunto ortonormal arbitrario}
	Sea $H$ un espacio de Hilbert y sea $S \subseteq H$ un conjunto ortonormal, luego:
	
	\begin{enumerate}
		\item Si $x \in H$ entonces $x_S = \Bigsum{u \in S}{\ip{x,u}u}$ esta bien definido
		\item Si $M = \ip{S}$ entonces $x \in M$ si y solo si $x = x_S$. Es m\'as si $x \in H$ entonces $x - x_S \in M^{\perp}$.
	\end{enumerate}
\end{theorem}

\begin{proof}
	\begin{enumerate}
		\item 	Dado $x \in H$, de \ref{Desigualdad de Bessel} sea $(u_n)$ una numeraci\'on de $S = \sett{u \in S \ / \ \ip{x,u}=0}$ y sea $(v_n)$ otra ordenaci\'on de los $u_n$; notemos $x_1 = \Bigsum{n}{\ip{x,u_n}u_n}$ y $x_2 = \Bigsum{n}{\ip{x,u_n}u_n}$ que por \ref{Proyeccion de un elemento en un ortonormal} y \ref{Desigualdad de Bessel} est\'an bien definidos.
	
	Luego:
	
	\[
	\begin{aligned}
		\ip{x_1 - x_2 , u_n} = & \ip{x_1,u_n} - \ip{x_2,u_n} \\
		\underbrace{=}_{u_n = v_{m_n} \text{ para alg\'un } m_n} & \ip{x,u_n} - \ip{x,v_{m_n}} \\
		= & \ip{x,u_n} - \ip{x,u_n}
		= & 0
	\end{aligned}
	\]
	
	Por ende, $\ip{x_1 - x_2,u_n} = \ip{x_1 - x_2,v_n} = 0 $ para todo $n \in \N$ y se concluye que $\ip{x_1 - x_2 , x_1 - x_2} = 0$ por lo que $x_1 = x_2$ y entonces $x_S$ esta bien definido y no depende del orden de la suma.
	
	\item Sea $x_{S_k} = \sum\limits_{i=1}^{k}\ip{x,u_i}u_i \in M$, luego como $M$ es cerrado se tiene que $x_{S_k} \rightarrow x_S \in M$. Ahora sea $s \in S$, entonces:
	
	\[
	\ip{x-x_S,v} = \ip{x,v} - \ip{x_S,v} = \ip{x,v} - \ip{x,v} = 0
	\]
	
	Por lo que $x - x_S \in M^{\perp}$. Finalmente, si $x \in M$ entonces como $x_S \in M$ entonces $x - x_S \in M \cap M^{\perp} = \sett{0}$, luego $x = x_S$. \qed
	
	\end{enumerate}
	
\end{proof}

\subsection{Conjuntos ortonormales completos}

\begin{definition}
	Sea $E$ un espacio vectorial con producto interno y sea $S \subseteq E$ ortonormal, diremos que $S$ es \textit{completo} si $S \subseteq T$ y $T$ es ortonormal, entonces $S = T$.
\end{definition}

\begin{proposition}
	\label{Ortogonal vacio es ser completo}
	Sea $S$ un conjunto ortonormal tal que $S^{\perp} = \sett{0}$, entonces $S$ es completo
\end{proposition}

\begin{proof}
	Sea $T$ ortonormal y sea $v \in T \setminus S$, luego $v \in S^{\perp} = 0$ por lo que $S$ es completo. \qed
\end{proof}

\begin{theorem}
	\label{Conjunto ortonormal completo genera en un Hilbert}
	Sea $E$ un espacio vectorial con producto interno, $S \subseteq E$ ortonormal y sea $M = \ip{S}$, entonces:
	
	\begin{enumerate}
		\item Si $M = E$ entonces $S$ es completo
		\item Si $S$ es completo y $E$ es de Hilbert entonces $M = E$
	\end{enumerate}
	
\end{theorem}

\begin{proof}
	\begin{enumerate}
		\item Si $x \in S^{\perp}$ entonces $x \in M^{\perp}=E^{\perp}=\sett{0}$, por lo tanto $S$ es completo
		\item Sea $x \in E$, luego por \ref{Proyeccion a un conjunto ortonormal arbitrario} $x_S$ esta bien definido y $x - x_S \in M^{\perp}$, luego como $S$ es completo $x - x_S = 0$ y por \ref{Proyeccion a un conjunto ortonormal arbitrario} se tiene que $x \in M$. \qed
	\end{enumerate}
\end{proof}

\begin{corollary}
	\label{Escritura de elemento de un HIlbert en un ortonormal completo}
	Sea $H$ de Hilbert y $S \subseteq H$ un conjunto ortonormal completo, luego si $x \in H$ entonces $x = \Bigsum{u \in S}{\ip{x,u}u}$.
\end{corollary}

\begin{proof}
	Como $H$ es Hilbert y $S$ es completo entonces por \ref{Conjunto ortonormal completo genera en un Hilbert} tenemos que $\ip{S} = H$, luego por \ref{Proyeccion a un conjunto ortonormal arbitrario} si $x \in H$ entonces $x = x_S$. \qed 
\end{proof}

\begin{theorem}[Identidad de Parseval]
	\label{Identidad de Parseval}
	Sea $E$ un espacio vectorial con producto interno y $S \subseteq E$ un conjunto ortonormal tal que para todo $x \in E$ vale:
	
	\begin{equation}
	\label{eq: Identidad de Parseval}
		\norm{x}^2 = \Bigsum{u \in S}{\abs{\ip{x,u}}^2}
	\end{equation}
	
	Luego $S$ es completo. M\'as a\'un si $E$ es Hilbert y $S$ es completo entonces vale \ref{eq: Identidad de Parseval}
\end{theorem}

\begin{proof}
	Sea $x \in E$ tal que $x \in S^{\perp}$, luego por \ref{eq: Identidad de Parseval} $\norm{x} = \Bigsum{u \in S}{\abs{\underbrace{\ip{x,u}}_{=0}}^2} = 0$, luego $x = 0$ y $S$ es completo.
	
	Si $E$ es Hilbert y $S$ es completo entonces por \ref{Escritura de elemento de un HIlbert en un ortonormal completo} y \ref{Desigualdad de Bessel} vale que $x = \Bigsum{n \in \N}{\ip{x,u_n}u_n}$ por lo que:
	
	\begin{equation*}
		\begin{aligned}
			\norm{x}^2 = & \ip{x,x}  \\
			= & \ip{\Bigsum{n \in \N}{\ip{x,u_n}u_n},\Bigsum{n \in \N}{\ip{x,u_n}u_n}} \\
			= & \Bigsum{n \in \N}{\ip{x,u_n}\overline{\ip{x,u_n}}} \\
			= & \Bigsum{n \in \N}{\abs{\ip{x,u_n}}^2} \\
			= & \Bigsum{u \in S}{\abs{\ip{x,u}}^2}
		\end{aligned}
	\end{equation*}
	\qed
\end{proof}

\begin{corollary}
	Sea $H$ Hilbert y $m \in M = \ip{S}$ con $S \subseteq H$ un conjunto ortonormal, luego $\norm{x-m} \geq \norm{x - x_S}$
\end{corollary}

\begin{proof}
	$\norm{x - m}^2 = \norm{\underbrace{x- x_S}_{\in M^{\perp}} + \underbrace{x_S - m}_{\in M}}^2 = \norm{x-x_S}^2 + \norm{x_S - M}^2 \geq \norm{x-x_S}^2$ \qed
\end{proof}

\subsection{Ortogonalizaci\'on de Gram Schmitt}

\begin{theorem}[Ortogonalizaci\'on de Gram-Schmidt]
	\label{Ortogonalizacion de GS}
	Sea $E$ un espacio vectorial con producto interno y sea $D$ un conjunto linealmente independiente no vac\'io, luego si $D$ es a lo sumo numerable existe $S	 \subseteq E$ ortonormal tal que:
	
	\begin{itemize}
		\item $\# S = \# D$
		\item $\ip{D} = \ip{S}$
	\end{itemize}
\end{theorem}

\begin{proof}
	Sea $D = \sett{x_n}$ y definamos:
	
	\[
		\begin{array}{cccccc}
			y_1 = & x_1 & \quad,\quad & u_1 = \dfrac{y_1}{\norm{y_1}} & \quad,\quad & S_1 = \sett{u_1} \\ 
			y_2 = & x_2 - x_{S_1} & \quad,\quad & u_2 = \dfrac{y_2}{\norm{y_2}} & \quad,\quad & S_2 = \sett{u_1,u_2} \\ 
			\vdots & \vdots & \quad,\quad & \vdots & \quad,\quad & \vdots \\ 
			y_n = & x_n - x_{S_{n-1}}  & \quad,\quad & u_n = \dfrac{y_n}{\norm{y_n}} & \quad,\quad & S_n = \sett{u_1, \dots, u_n} \\ 
		\end{array}
	\]
	
	Luego sea $S = \Bigcup{n \in \N}{S_n}$ y es claro verificar ambas propiedades. \qed
	
\end{proof}

\begin{proposition}
	\label{Aproximacion por ortonormal separable en Hilbert separable}
	Sea $E$ un espacio vectorial con producto interno de dimensi\'on infinita, luego si $E$ es separable existe $S \subseteq E$ ortonormal, completo y numerable tal que $\overline{\ip{S}} = E$.
\end{proposition}

\begin{proof}
	Como $E$ es separable existe $D = \sett{x_n} \subseteq E$ denso numerable. Sea $n_1 = \min\sett{n \in \N \ / \ x_n \neq 0}$ y $y_1 = x_{n_1}$ e inductivamente sea $n_k = \min\underbrace{\sett{n \in \N \ / \ x_n \not \in \ip{y_1, \dots, y_{k-1}} \ , \ n_k > n_{k-1}}}_{A_k}$ y $y_k = x_{n_k}$ , luego por la buena ordenaci\'on de $\N$ y el hecho que $D$ es denso y $dim(E)= \infty$ entonces $A_k \neq \emptyset$ para todo $k \in \N$ por lo que $n_k$ esta bien definido. Sea $Y = \Bigcup{k \in \N}{\sett{y_k}}$
	
	\begin{lemma}
		\label{Lemma: Aproximacion por ortonormal separable en Hilbert separable}
		$\ip{D} = \ip{Y}$ e $Y$ es linealmente independiente.
	\end{lemma}
	
	\begin{proof}[Demostraci\'on (del Lema)]
		
		Si $x_{n_0} \in D$ luego si $n_0 = n_k$ para alg\'un $k$ se concluye que $x_{n_0} \in Y$, si no entonces por Arquimedianidad $A = \sett{n \in \N \ / \ n > n_0 \ , \ \exists k \in \N \ , \ n = n_k \ } \neq \emptyset$ y sea $\hat{k} = \min A$; luego $x_{n_0} \in \ip{A_{\hat{k}-1}} \subseteq \ip{Y}$. Se concluye que $D \subseteq \ip{Y}$ y entonces $\ip{D} \subseteq \ip{Y}$.
		
		Rec\'iprocamente sea $y \in Y$, luego por definici\'on de $y$ se tiene que $y = x_{n_k} \in \ip{D}$ para alg\'un $k$ y entonces $Y \subseteq \ip{D}$ por lo que $\ip{Y} = \ip{D}$.
		
		Finalmente por construcci\'on $Y$ es linealmente independiente. \qed  
		
	\end{proof}
	
	Luego por \ref{Ortogonalizacion de GS} existe $S \subseteq E$ ortonormal tal que $\ip{S} = \ip{Y} \underbrace{=}_{\ref{Lemma: Aproximacion por ortonormal separable en Hilbert separable}} \ip{D}$, y como $D$ es denso se tiene que $\overline{\ip{S}} = \overline{\ip{D}} \supseteq \overline{D} = E$. \qed
	
	
\end{proof}

\subsection{Dimensi\'on de un espacio de Hilbert}

\begin{proposition}
	\label{Dos sistemas ortonormales y completos tienen el mismo cardinal}
	Sea $E$ un espacio vectorial con producto interno y sean $S_1,S_2 \subseteq E$ conjuntos ortonormales y completos, luego $\# S_1 = \# S_2$ 
\end{proposition}

\begin{proof}
	Si $S_1$ es finito entonces $S = \sett{u_1, \dots, u_k}$, sea $x \in E$ entonces $x - x_{S_1} = x - \sum\limits_{i=1}^{k}{\ip{x,u_i}u_i} \in S_1^{\perp} = \sett{0}$ por lo que $S_1$ es generador y ortonormal; conclu\'imos que $S_1$ es base y $\dim_E = k$. An\'alogamente $S_2 = \sett{v_1 , \dots , v_j}$ es base y finalmente sea $T \in End(E)$ dada por $T(u_i) = v_i$, luego $T$ es biyectiva y $\# S_1 = \# S_2$ .
	
	Si $S_1$ es infinito entonces para $x \in S_1$ sea $S_2(x) = \sett{u \in S_2 \ / \ \ip{u,x} \neq 0}$, luego por \ref{Desigualdad de Bessel} sabemos que $S_2(x)$ es a lo sumo numerable.
	
	\begin{lemma}
		$\Bigcup{x \in S_1}{S_2(x)} = S_2$
	\end{lemma}
	
	\begin{proof}[Demostraci\'on (del Lema)]
		Supongamos que existe $y \in S_2$ tal que $y \not \in S_2(x)$ para todo $x \in S_1$, luego $y \in S_{1}^{\perp} = \sett{0}$; conclu\'imos que $S_2 \subseteq \Bigcup{x \in S_1}{S_2(x)}$ pues $S_2$ es ortonormal.
		
		Trivialmente se da la otra inclusi\'on. \qed
	\end{proof}
	
	Por lo tanto $\# S_2 \leq \# \left(\N \times S_1\right) = \# S_1$; an\'alogamente $\# S_1 \leq \# S_2$ y se concluye el resultado. \qed
	
\end{proof}

\begin{definition}
	Se define $dim(E) = \# S$ donde $S \subseteq E$ es un sistema ortonormal completo.
\end{definition}

\begin{definition}
	Sean $E$ y $F$ dos espacios vectoriales con producto interno, decimos que son \textit{congruentes} si existe $T \in L(E,F)$ isomorfismo tal que $\norm{T(x)}_{F} = \norm{x}_E$
\end{definition}

\begin{definition}
	Sea $Q \neq \emptyset$, luego definimos $l^2(Q) = \sett{f : Q \rightarrow \R \ / \ \# \sett{q \in Q \ / \ f(q) \neq 0} \leq \aleph_0 \ , \ \Bigsum{q \in Q}{\abs{f(q)}^2} < \infty}$.
\end{definition}

\begin{proposition}
	Valen:
	
	\begin{enumerate}
		\item $l^2(Q)$ es un espacio de Hilbert con producto interno dado por $\ip{f,g} = \Bigsum{q \in Q}{f(q)\overline{g(q)}}$
		\item Sea $S = \sett{\chi_{\sett{q}}}_{q \in Q}$ es ortonormal y completo
		\item Si $\# Q > \# \N$ entonces $l^2(Q)$ no es separable
	\end{enumerate}
	
\end{proposition}

\begin{proposition}
	\label{Existencia de sistema ortonormal completo}
	Todo espacio vectorial con producto interno admite un sistema ortonormal completo.
\end{proposition}

\begin{proof}
	Sea $P = \sett{S \subseteq E \ / \ S \text{ ortonormal}}$ y dotemoslo del orden dado por la inclusi\'ion, luego $P \neq \emptyset$ pues si $v \in E$ entonces $\sett{v} \in P$.
	
	Sea $\sett{S_i}$ una colecci\'on de subconjuntos de $P$ totalmente ordenada y sea $T = \Bigcup{i \in I}{S_i}$, luego es claro que $S_i \leq T$; faltar\'ia ver que $T \in P$.
	
	Para eso sean $v_1,v_2 \in T$, luego existe $S_i$ tal que $v_1,v_2 \in S_i$ y como este es ortonormal resulta que $\ip{v_1,v_2} = 0$ y $\norm{v_1} = \norm{v_2} = 1$. Conclu\'imos que $T \in P$, luego por \ref{Lema de Zorn} existe $M \in P$ elemento maximal.
	
	Finalmente sea $v \in M^{\perp}$, luego $M \cup \sett{\dfrac{v}{\norm{v}}}$ ser\'ia un conjunto ortonormal lo que contradice la maximalidad de $M$; por ende no existe tal $v$ y $M$ resulta completo. \qed
\end{proof}

\begin{theorem}
	\label{HIlbert congruente a un l2}
	Sea $H$ Hilbert tal que $\dim H = \alpha$ entonces $H \cong l^2(Q)$ con $\# Q = \alpha$
\end{theorem}

\begin{proof}
	Sea $S_{\alpha} = \sett{u_i}_{i \in Q}$ un sistema ortonormal, completo de $H$ que existe por \ref{Existencia de sistema ortonormal completo}; luego $x \in H$ entonces $x = \Bigsum{i \in Q}{\ip{x,u_i}u_i}$, y debido a \ref{Identidad de Parseval} y \ref{Desigualdad de Bessel} $\sett{\ip{x,u_i}}_{i \in Q} \subset l^2(Q)$. Definimos $T : H \rightarrow l^2(Q)$ dado por $T(x) = (\ip{x,u_i})_{i \in Q}$ y veamos que es la indicada.
	
	\begin{enumerate}
		\item $T$ es lineal
		
		Sean $x,y \in H$ y $\lambda \in \mathbb{F}$, luego $T(x + \lambda y) = \left(\ip{x+\lambda y , u_i}\right) = \left( \ip{x,u_i} + \lambda \ip{y,u_i} \right) = T(x) + \lambda T(y)$.
		
		\item $T$ es monomorfismo
		
		Si $T(x) = (0)$ luego $\ip{x,u_i} = 0$ para todo $i \in Q$, luego $x \in S^{\perp} = \sett{0}$ pues $S$ es completo.
		
		\item $T$ es epimorfimso
		
		Si $(c_i) \in l^2(Q)$ luego por \ref{Proyeccion de un elemento en un ortonormal} $x = \Bigsum{i \in Q}{c_i u_i} \in H$ y $T(x) = (c_i)$
		
		\item $T$ es isometr\'ia
		
		Por \ref{Identidad de Parseval}
		
	\end{enumerate}
	\qed
\end{proof}


\begin{corollary}
	Sea $H$ Hilbert separable de dimensi\'on infinita, luego $H$ es congruente a $l^2$
\end{corollary}

\subsection{Proyecci\'on ortogonal}

\begin{example}
	El sistema $\sett{\dfrac{e^{int}}{\sqrt{2 \pi}} \ , \ t \in [0,2 \pi]}_{n \in \N}$ es completo.
\end{example}

\begin{proof}
	Supongamos que $\int_{-\pi}^{\pi}{f(t)e^{int} dt} = 0$ para todo $n \in \N$ y sea $g(t) = \int_{-\pi}^{t}{f(t) dt}$, luego $g$ es continua y $g' = f$ ctp por el teorema de diferenciaci\'on de Lebesgue. Notemos que:
	
	\[
	\begin{aligned}
		g(\pi) = & \int_{-\pi}^{\pi}{f(t) dt} = \int_{-\pi}^{\pi}{f(t) e^{i0t}dt} = 0 = g(-\pi) \\
		\int_{-\pi}^{\pi}{g(t) e^{int} dt} = & \dfrac{g(t)e^{int}}{ni} \vert_{-\pi}^{\pi} - \dfrac{\int_{-\pi}^{\pi}{f(t)e^{int}}}{in} = 0
	\end{aligned}	
	\]
	
	Por lo tanto tenemos que $\int_{-\pi}^{\pi}{g(t)e^{int}dt} = 0$ donde $g$ es continua y $g(-\pi) = g(\pi) = 0$, por Stone-Weirstrass existe $(p_n)_{n \in \N}$ sucesi\'on de polinomios trigonom\'etricos tal que $p_n \rightrightarrows g$, por lo tanto:
	
	\begin{equation*}
		\int_{-\pi}^{\pi}{p_k(t)e^{int}} \rightarrow \int_{-\pi}^{\pi}{g(t)e^{int}dt} = 0 \quad n \in \N
	\end{equation*}
	
	No obstante, si $p_k \neq cte$ entonces para todo $k \in \N$ $\ip{p_k,e^{int}} \neq 0$ para alg\'un $n$, luego $p_k = cte = g(\pi) = 0$. Conclu\'imos que $g = 0$ y entonces $f = 0$ ctp. \qed
	
\end{proof}

\begin{theorem}
	\label{Proyeccion unica en un cerrado convexo}
	Sea $H$ Hilbert y $K$ cerrado y convexo, luego si $x \in H$ entonces existe un \'unico $k \in K$ tal que $\norm{x-k} = d(x,K)$
\end{theorem}

\begin{proof}
	Sea $d_n = \norm{x-k_n}$ una sucesi\'on minimizante, luego para todo $n \geq N \in \N$ vale que $d + \frac{1}{N} \geq \norm{x-k_n}$ por lo que por \ref{Ley del paralelogramo}:
	
	\begin{equation*}
		\norm{(x-k_n) - (x-k_m)}^2 + \norm{(x-k_n) + (x-k_m)}^2 =  2 \norm{x-k_n}^2 + 2 \norm{x-k_m}^2
	\end{equation*}
	
	Por lo tanto:
	
	\[
	\begin{aligned}
		\norm{k_n-k_m}^2 = & 2 \norm{x-k_n}^2 + 2 \norm{x-k_m}^2  - \norm{2x-k_n -k_m}^2 \\
		= & 2 \norm{x-k_n}^2 + 2 \norm{x-k_m}^2  - 4\norm{x- \underbrace{\dfrac{k_n -k_m}{2}}_{\in K}}^2 \\
		\leq & 2 \left(d + \frac{1}{n}\right)^2 + 2 \left(d + \frac{1}{m}\right)^2 - 4d^2 \\
		= & \frac{4d}{n} + \frac{2}{n^2} + \frac{4d}{m} + \frac{2}{m^2} \quad  \overrightarrow{n,m \rightarrow \infty} \quad 0
	\end{aligned}
	\]
	
	Luego $(k_n)$ es de Cauchy y como $H$ es completo existe $k \in K$ tal que $k_n \rightarrow K$; por \ref{Prod interno es continuo} $d = \norm{x-k}$. Si $h \in K$ tal que $\norm{x-h} = d$ luego como $K$ es convexo $\frac{k+h}{2} \in K$ por lo que:
	
	\[
	d \leq \norm{x-\frac{k+h}{2}} \leq \dfrac{\norm{x-k} + \norm{x-h}}{2} = d
	\]
	
	Luego por \ref{Ley del paralelogramo}:
	
	\[
		\norm{k-h}^2 = 2 \norm{x-k}^2 + 2 \norm{x-h}^2  - 4\norm{x- \dfrac{k -h}{2}}^2 = 0 \\
	\]
	
	Por lo que $k = h$. \qed
\end{proof}

\begin{definition}
	Sea $M \subseteq H$ un subespacio cerrado de $H$ Hilbert, luego por \ref{Proyeccion unica en un cerrado convexo} existe un \'unico $f_0 \in M$ tal que para todo $x \in H$ vale $\norm{x-f_0} = d(x,M)$. A su vez como $M$ es cerrado tambi\'en es un espacio de Hilbert, luego por \ref{Existencia de sistema ortonormal completo} existe $S \subseteq M$ tal que $M = \ip{S}$, finalmente por \ref{Proyeccion de un elemento en un ortonormal} vale que $f_0 = x_S$.
	
	En resumen, dado $M \subseteq H$ subespacio cerrado y $h \in H$ existe un \'unico elemento $f_0$ tal que $h - f_0 \in M^{\perp}$. Definimos la \textit{proyecci\'on ortogonal sobre } $M$ $P_M:H \rightarrow M$ dado por $P_M(h) = f_0$.
\end{definition}

\begin{proposition}
	\label{Propiedades proyeccion ortogonal}
	Sea $M \subseteq H$ un subespacio cerrado en un Hilbert, sea $h \in H$ y $Ph := P_M(h)$ el \'unico elemento tal que $h - Ph \in M^{\perp}$, luego:
	
	\begin{enumerate}
		\item $P$ es lineal
		\item $\norm{Ph} \leq \norm{h}$
		\item $P^2 = P$
		\item $\ker P = M^{\perp}$ y $ran P = M$
	\end{enumerate}
	
	\begin{proof}
		\begin{enumerate}
			\item Sean $x,y \in H$, $\lambda \in \mathbb{F}$ y $m \in M$; luego $\ip{x + \lambda y - Px + \lambda Py, f} = \ip{x -Px,f} + \lambda \ip{y - Py,f} = 0$. Por unicidad en \ref{Proyeccion unica en un cerrado convexo} vale que $P(x + \lambda y) = Px + \lambda Py$.
		
		\item Notemos que $\norm{h}^2 = \norm{\underbrace{h - Ph}_{\in M^{\perp}} + \underbrace{Ph}_{\in M}}^2 = \norm{h-Ph}^2 + \norm{Ph}^2 \geq \norm{Ph}^2$.
		
		\item Como $P\vert_M = Id_M$ entonces $P(Ph) = Ph$ para todo $h \in H$.
		
		\item Si $Ph = 0$ entonces $h - Ph = h \in M^{\perp}$; rec\'iprocamente si $h \in M^{\perp}$ entonces $h-0 \in M^{\perp}$ por lo que $h \in \ker P$. \qed
	\end{enumerate}
	\end{proof}
	
\end{proposition}

\begin{corollary}
	Sea $M \subseteq H$ un subespacio cerrado en un Hilbert, entonces $(M^{\perp})^{\perp} = M$
\end{corollary}

\begin{proof}
	Primero notemos que:
	
	\begin{lemma}
		$Id - P_M = P_{M^{\perp}}$
	\end{lemma}
	
	\begin{proof}[Demostraci\'on del lema]
		Sea $m \in M^{\perp}$ y $h \in H$, luego $\ip{h - (Id - P_M)(h),m} = \ip{h - h + P_M(h),m} = \ip{P_M(h),m} = 0$, por la unicidad de \ref{Proyeccion unica en un cerrado convexo} vale que $P_{M^{\perp}} = Id - P_M$. \qed
	\end{proof}
	
	Luego por \ref{Propiedades proyeccion ortogonal} vale que $\left(M^{\perp}\right)^{\perp} = \ker P_{M^{\perp}} = \ker (Id - P_M) \underbrace{=}_{0 = h - Ph \Leftrightarrow h = Ph } ran \ P = M$. \qed
	
\end{proof}

\begin{corollary}
	\label{Calculo del doble complemento ortogonal}
	Sea $A \subseteq H$  un conjunto en un Hilbert, luego $(A^{\perp})^{\perp} = \overline{\ip{A}}$
\end{corollary}

\begin{proof}
	Para esto vamos a utilizar dos lemas:
	
	\begin{lemma}
		\label{Lemma1: Calculo del doble complemento ortogonal}
		$\ip{A}^{\perp} = A^{\perp}$
	\end{lemma}
	
	\begin{proof}
		Por un lado si $f \in A^{\perp}$ luego $\ip{f, \sum\limits_{i=1}^{n}{c_i a_i}} = \sum\limits_{i=1}^{n}{c_i\ip{f,a_i}} = 0$ por lo que $f \in \ip{A}^{\perp}$.
		
		Rec\'iprocamente si $f \in \ip{A}^{\perp}$ y sea $a \in A$, luego $\ip{f,\underbrace{a}_{A \subseteq \ip{A}}} = 0$ por lo que $f \in A^{\perp}$. \qed
		
	\end{proof}
	
	\begin{lemma}
		\label{Lemma2: Calculo del doble complemento ortogonal}
		Sea $U \subseteq H$ un conjunto en un Hilbert, entonces $U^{\perp} = \overline{U}^{\perp}$.
	\end{lemma}
	
	\begin{proof}
		Sea $h \in U^{ \perp}$, luego si $u \in \overline{U}$ entonces existe $\sett{u_n}_{n \in \N} \subset U$ tal que $u_n \rightarrow u$. Por \ref{Prod interno es continuo} entonces $0 = \ip{h,u_n} \rightarrow \ip{h,u}$ por lo que $h \in \overline{U}^{\perp}$.
		
		Rec\'iprocamente, si $h \in \overline{U}^{\perp}$ y $u \in U \subseteq \overline{U}$ entonces $\ip{h,u} = 0$; conclu\'imos que $h \in U^{\perp}. \qed$
	\end{proof}
	
	Luego por el corolario previo $\overline{\ip{A}} = \left(\overline{\ip{A}}^{\perp}\right)^{\perp} \underbrace{=}_{\ref{Lemma2: Calculo del doble complemento ortogonal}} \left({\ip{A}}^{\perp}\right)^{\perp} \underbrace{=}_{\ref{Lemma1: Calculo del doble complemento ortogonal}} \left({{A}}^{\perp}\right)^{\perp} $. \qed
	
\end{proof}

\begin{corollary}
	\label{Variedad es densa si el complemento es vacio}
	Sea $M \subseteq H$ una variedad lineal en un Hilbert, luego $M$ es denso si y s\'olo si $M^{\perp} = \sett{0}$
\end{corollary}

\begin{proof}
	Si $\overline{M} = H$ entonces $M^{\perp} \underbrace{=}_{\ref{Lemma2: Calculo del doble complemento ortogonal}} = \overline{M}^{\perp} = H^{\perp} = \sett{0}$.
	
	Rec\'iprocamente de \ref{Calculo del doble complemento ortogonal} sabemos que $\overline{M} = \left(M^{\perp}\right)^{\perp} = \sett{0}^{\perp} = H$. \qed
\end{proof}

\subsection{Teorema de representaci\'on de Riesz}

\begin{proposition}
	\label{Continuidad de un funcional}
	Sea $H$ un espacio de Hilbert y sea $L : H \rightarrow \mathbb{F}$ un funcional lineal, entonces son equivalentes:
	
	\begin{enumerate}
		\item $L$ es continua
		\item $L$ es continua en 0
		\item $L$ es continua en alg\'un punto
		\item Existe $c > 0$ tal que:
		
		\begin{equation}
		\label{eq: Funcional acotado}
			\abs{L(h)} \leq c \norm{h} \quad \forall h \in H
		\end{equation}  
	\end{enumerate}
\end{proposition}

\begin{proof}
	Es claro que $1) \Longrightarrow 2) \Longrightarrow 3)$ y que $4) \Longrightarrow 2)$, veamos las que faltan:
	
	\begin{enumerate}
		\item[$3) \Longrightarrow 1)$]Supongamos que $L$ es continua en $h_0 \in H$ y sea $h \in H$; luego si $h_n \rightarrow h$ entonces $h_n - h + h_0 \rightarrow h_0$, por lo tanto $L(h_0) = \lim L(h_n - h + h_0) = \lim L(h_n) - L(h) + L(h_0)$ y conclu\'imos que $L(h) = \lim L(h_n)$.
		
		\item[$ 2) \Longrightarrow 4) $] Como $L$ es continua en $0$ entonces si $V = \sett{\alpha \in \mathbb{F} \ / \ \abs{\alpha} < 1}$ entonces $L^{-1}(V)$ es abierto; es decir existe $\delta > 0$ tal que $\norm{h} < \delta$ implica $\abs{L(h)} < 1$.
		
		Si $h \in H$ y $\epsilon > 0$ entonces $\norm{\dfrac{\delta h}{\norm{h} + \epsilon}} < \delta$ por lo que:
		
		\[
			1 > \abs{L\left[\dfrac{\delta h}{\norm{h} + \epsilon}\right]} = \dfrac{\delta}{\norm{h} + \epsilon} \abs{L(h)}
		\]
		
		Por lo que si $\epsilon \rightarrow 0$:
		
		\[
			\abs{L(h)} < \dfrac{1}{\delta} \left(\norm{h}\right) := c \norm{h}
		\]
		\qed
	\end{enumerate}
\end{proof}

\begin{definition}
	Decimos que $L : H \rightarrow \mathbb{F}$ es \textit{acotado} si vale \ref{eq: Funcional acotado}. De \ref{Continuidad de un funcional} vemos que un funcional es acotado si y s\'olo si es continuo.
	
	En ese caso definimos:
	
	\begin{equation*}
		\norm{L} = \sup \sett{\abs{L(h)}: \ \norm{h} \leq 1}
	\end{equation*}
	
\end{definition}

\begin{proposition}
	Si $L$ es un funcional acotado entonces:
	\begin{equation}
	\label{eq: Normas equivalentes de un funcional}
	\begin{aligned}
		\norm{L} := & \sup \sett{\abs{L(h)}: \ \norm{h} \leq 1} \\
		= & \sup \sett{\abs{L(h)}: \ \norm{h} = 1}\\
		= & \sup \sett{\dfrac{\abs{L(h)}}{\norm{h}}: \ h \neq 0}  \\
		= & \inf \sett{c > 0: \ \abs{L(h)} \leq c \norm{h} \ h \in H} 
	\end{aligned}	
	\end{equation}
	
	Es m\'as, vale que $\abs{L(h)} \leq \norm{L} \norm{h}$ para todo $h \in H$.
	
\end{proposition}

\begin{proof}
	Notemos(solo por esta demostraci\'on):
	
	\[
	\begin{array}{ccc}
	 \norm{L}_2 & = & \sup \sett{\abs{L(h)}: \ \norm{h} = 1} \\
	 \norm{L}_3 & = & \sup \sett{\dfrac{\abs{L(h)}}{\norm{h}}: \ h \neq 0} \\
	 \norm{L}_4 & =  & \inf \sett{c > 0: \ \abs{L(h)} \leq c \norm{h} \ h \in H}
	\end{array}
	\]
	
	Vamos por partes, 
	
	\begin{itemize}
		\item Primero como $\sett{\abs{L(h)}: \ \norm{h} = 1} \subseteq \sett{\abs{L(h)}: \ \norm{h} \leq 1}$ entonces vale que $\norm{L}_2 \leq \norm{L}$. 
		
		Rec\'iprocamente, si $\norm{h} \leq 1$ entonces:
		
		\begin{equation*}
		\begin{array}{cc}
		& \abs{L\left(\dfrac{h}{\norm{h}}\right)} \leq \norm{L}_2 \\
		\Longrightarrow &	\dfrac{1}{\norm{h}}\abs{L(h)} \leq \norm{L}_2 \\
		\Longrightarrow &	\abs{L(h)} \leq \norm{L}_2 \norm{h} \leq \norm{L}_2 \\
		\Longrightarrow &	\sup\limits_{\norm{h} \leq 1} \abs{L(h)} \leq \norm{L}_2 \\
		\Longrightarrow &	\norm{L} \leq \norm{L}_2
		\end{array}
		\end{equation*}
		
		\item Si $h \neq 0$ entonces:
		
		\begin{equation*}
		\begin{array}{cc}
		& \abs{L\left(\dfrac{h}{\norm{h}}\right)}  \leq \norm{L}_2 \\
		\Longrightarrow &	\dfrac{1}{\norm{h}}\abs{L(h)} \leq \norm{L}_2 \\
		\Longrightarrow &	\sup\limits_{h \neq 0} \sett{\dfrac{1}{\norm{h}}\abs{L(h)}} \leq \norm{L}_2 \\
		\Longrightarrow &	\norm{L}_3 \leq \norm{L}_2
		\end{array}
		\end{equation*}
		
		Rec\'iprocamente notemos que $\sett{\abs{L(h)}: \ \norm{h} = 1} = \sett{\dfrac{\abs{L(h)}}{\norm{h}}: \ \norm{h} = 1} \subseteq \sett{\dfrac{\abs{L(h)}}{\norm{h}}: \ h \neq 0}$ por lo tanto $\norm{L}_2 \leq \norm{L}_3$.
		
		\item Sea $\epsilon > 0$, luego:
		
		\begin{equation*}
		\begin{array}{cc}
		& \abs{L\left(\dfrac{h}{\norm{h} + \epsilon}\right)} \leq \norm{L} \\
		\Longrightarrow  & \abs{L(h)} \leq \left(\norm{h} + \epsilon\right) \norm{L} \\
		\text{Si } \epsilon \rightarrow 0 \Longrightarrow  & \abs{L(h)} \leq \norm{L} \norm{h} \\
		\Longrightarrow  & \norm{L}_4 \leq \norm{L}
		\end{array}
		\end{equation*}
		
		Rec\'iprocamente, si $\norm{L(h)} \leq c \norm{h}$ entonces $\norm{L} \leq c$ por lo que $\norm{L} \leq \norm{L}_4$. \qed
		
	\end{itemize}
\end{proof}

\begin{theorem}[Teorema de Representaci\'on de Riesz]
	Sea $L : H \rightarrow \mathbb{F}$ un funcional, entonces $L$ es acotado si y s\'olo si existe un \'unico $h_0 \in H$ tal que $L(h) = \ip{h,h_0}$. En ese caso $\norm{L} = \norm{h_0}$.
\end{theorem}

\begin{proof}
	Sea $M = \ker L$, como $L$ es acotada entonces $M$ es cerrado y como $L \neq 0$ (en cuyo caso $h_0 = 0$) entonces $M^{\perp} \neq \sett{0}$. Como $H = M \oplus M^{\perp}$ entonces existe $f_0 \in M^{\perp}$ tal que $L(f_0) = 1$.
	
	Sea $h \in H$, entonces $L(h - L(h)f_0) = 0$ por lo que $h - L(h)f_0 \in M$; de aqu\'i conclu\'imos:
	
	\begin{equation*}
	\begin{array}{cccc}
	& 0 & = & \ip{h - L(h)f_0, f_0} \\
	\Longrightarrow & 0 & = & \ip{h,f_0} - L(h)\norm{f_0}^2 \\
	\Longrightarrow & L(h) & = & \dfrac{1}{\norm{f_0}^2}\ip{h,f_0} \\
	\Longrightarrow & L(h) & \underbrace{=}_{h_0 = \dfrac{f_0}{\norm{f_0}^2}} & \ip{h,h_0} 
	\end{array}
	\end{equation*}
	
	Si $h_0'$ es tal que $\ip{h,h_0} = L(h) = \ip{h,h_0'}$ entonces $0 = \ip{h,h_0 - h_0'}$ para todo $h \in H$, en particular $0 = \ip{h_0 - h_0',h_0 - h_0'} = \norm{h_0 - h_0'}^2$ por lo que $h_0 = h_0'$.
	
	Rec\'iprocamente, si $L(h) = \ip{h,h_0}$ entonces por \ref{Desigualdad de Cauchy-Schwartz } $\abs{L(h)} \leq \norm{h} \norm{h_0}$ por lo tanto $\norm{L} \leq \norm{h_0}$.
	
	En ese caso, $L\left(\dfrac{h_0}{\norm{h_0}}\right) = \dfrac{1}{\norm{h_0}}\ip{h_0,h_0} = \norm{h_0}$ por lo que $\norm{L} = \norm{h_0}$. \qed
	
\end{proof}

\section{Espacios de Banach}

\subsection{Operadores entre espacios normados}

\begin{proposition}
	\label{La norma es continua}
	Sea $E$ un espacio normado, entonces:
	
	\begin{enumerate}
		\item La suma es continua
		\item El producto por un escalar es continuo
		\item La norma es continua
	\end{enumerate}
\end{proposition}

\begin{proof}
	\begin{enumerate}
		\item Si $x_n \rightarrow x$ y $y_n \rightarrow y$ entonces $\norm{x+y - x_n - y_n} \leq \norm{x_n -x} + \norm{y_n -y} \rightarrow 0$
		\item Si $x_n \rightarrow x$ y $\lambda \in \mathbb{F}$ entonces $\norm{\lambda x_n - \lambda x} = \abs{\lambda} \norm{x_n - x} \rightarrow 0$.
		\item Si $x_n \rightarrow x$ entonces por definici\'on $\norm{x_n -x} \rightarrow 0$. \qed
	\end{enumerate}
\end{proof}

\begin{proposition}
	Sea $E$ un espacio normado y $x_0 \in E$ entonces $\overline{B_r(x_0)} = B_r[x_0]$.
\end{proposition}

\begin{proof}
	Si $x \in \overline{B_r(x_0)}$ entonces existe $\sett{x_n} \subset B_r(x_0)$ tal que $x_n \rightarrow x$, como $\norm{x_n - x_0} < r$ entonces por \ref{La norma es continua} se tiene que $\norm{x_n - x_0} \rightarrow \norm{x - x_0}$ por lo que $x \in B_r[x_0]$.
	
	Rec\'iprocamente si $x \not \in \overline{B_r(x_0)}$ entonces existe $\epsilon > 0$ tal que $B_{\epsilon}(x) \cap B_r(x_0) = \emptyset$; luego $\norm{x - x_0} > \epsilon + r > r$ por lo que $x \not \in B_{r}[x_0]$. \qed
\end{proof}

\begin{theorem}
	\label{Banach si y solo si abs convergente es convergente}
	Sea $X$ un espacio normado, entonces $X$ es de Banach si y s\'olo si vale:
	
	\begin{equation}
		\label{eq: Condicion de Banach}
		\text{Si } \left(x_n\right) \text{ cumple que } \Bigsum{n \in \N}{\norm{x_n}} < \infty \ \Longrightarrow \ \Bigsum{n \in \N}{x_n} \in X
	\end{equation}
	
\end{theorem}

\begin{proof}
	Sea $S_k = \Bigsum{n \leq k}{x_n}$, entonces si $k > k'$, $\norm{S_{k} - S_{k'}} = \norm{\sum\limits_{n = k'+1}^{k}{x_n}} \leq \sum\limits_{n = k'+1}^{k}{\norm{x_n}} \ \underrightarrow{k,k' \rightarrow \infty} \ 0$. Luego $S_k$ es de Cauchy y como $X$ es Banach $S_k \rightarrow \Bigsum{n \in \N}{x_n} \in X$.
	
	Rec\'iprocamente, sea $\left(x_n\right) \subset X$ de Cauchy y para cada $k \in \N$ sea $\epsilon = \frac{1}{2^k}$ y $n_k \in \N$ tal que $\norm{x_{n} - x_m} < \frac{1}{2^k}$ si $n,m \geq n_k$. Luego si $z_k = x_{n_{k+1}} - x_{n_k}$ entonces $\Bigsum{k}{\norm{z_k}} < \Bigsum{k}{\frac{1}{2^k}} < \infty$; luego por hip\'otesis $S_m = \sum\limits_{k=1}^{m}{z_k}$ converge, pero $S_m = x_{n_{m+1}} - x_{n_1}$, luego $\lim\limits_{m} {x_{n_m}} = x_{n_1} + \lim S_m \in X$; como $x_n$ es de Cauchy y tiene una subsucesi\'on convergente entonces $(x_n)$ es convergente. \qed
	
\end{proof}

\begin{definition}
	Si $X,Y$ son espacios normados un \textit{isomorfismo topol\'ogico} es $T : X \rightarrow Y$ tal que:
	
	\begin{itemize}
		\item $T$ es isomorfismo lineal
		\item $T$ y $T^{-1}$ son continuas
	\end{itemize}
	
\end{definition}

\begin{proposition}
	\label{Continuidad de un operador}
	Seax $X,Y$ espacios normados y sea $T : X \rightarrow Y$ un operador lineal, entonces son equivalentes:
	
	\begin{enumerate}
		\item $T$ es continua
		\item $T$ es continua en 0
		\item $T$ es continua en alg\'un punto
		\item Existe $c > 0$ tal que:
		
		\begin{equation}
		\label{eq: Operador acotado}
		\norm{T(x)}_Y \leq c \norm{x}_X \quad \forall x \in X
		\end{equation}
		\item $T$ est\'a acotado en $B_1[0]$
		\item $T$ est\'a acotado en $B_r[x_0]$ para todos $x_0 \in X$ y $r > 0$
		\item $T$ est\'a acotado en $\partial B_r[x_0]$ para todos $x_0 \in X$ y $r > 0$
	\end{enumerate}
\end{proposition}

\begin{proof}
	Es claro que $1) \Longrightarrow 2) \Longrightarrow 3)$, que $4) \Longrightarrow 2)$ y que $6) \Longrightarrow 7)$, veamos las que faltan:
	
	\begin{enumerate}
		\item[$3) \Longrightarrow 1)$] Supongamos que $T$ es continua en $x_0 \in X$ y sea $x \in X$; luego si $x_n \rightarrow x$ entonces $x_n - x + x_0 \rightarrow x_0$, por lo tanto $T(x_0) = \lim T(x_n - x + x_0) = \lim T(x_n) - T(x) + T(x_0)$ y conclu\'imos que $T(x) = \lim T(x_n)$.
		
		\item[$ 2) \Longrightarrow 4) $] Como $T$ es continua en $0$ entonces si $V = \sett{y \in Y \ / \ \norm{y}_Y < 1}$ entonces $T^{-1}(V)$ es abierto; es decir existe $\delta > 0$ tal que $\norm{x}_X < \delta$ implica $\norm{T(x)}_Y < 1$.
		
		Si $x \in X$ y $\epsilon > 0$ entonces $\norm{\dfrac{\delta x}{\norm{x}_X + \epsilon}}_X < \delta$ por lo que:
		
		\[
		1 > \norm{T\left[\dfrac{\delta x}{\norm{x}_X + \epsilon}\right]}_Y = \dfrac{\delta}{\norm{x}_X + \epsilon} \norm{T(x)}_Y
		\]
		
		Por lo que si $\epsilon \rightarrow 0$:
		
		\[
		\norm{T(x)}_Y < \dfrac{1}{\delta} \left(\norm{x}_X\right) := c \norm{x}_X
		\]
		
		\item[$ 4) \Longrightarrow 5) $] Sea $x \in B_1[0]$, luego $\norm{T(x)}_Y \leq c \norm{x}_X \leq c$.
		
		\item[$ 5) \Longrightarrow 6) $] Sea $r > 0$ y $x_0 \in X$, luego si $x \in B_r[x_0]$ entonces existe $M > 0$ tal que $\norm{T\left(\dfrac{x- x_0}{r}\right)}_Y \leq M$ pues $\dfrac{x- x_0}{r} \in B_1[0]$
		
		Por lo tanto $\norm{T(x) - T(x_0)}_Y \leq Mr$ lo que implica que $\norm{T(x)}_Y \leq rM + \norm{T(x_0)}_Y := C$.
		
		\item[$ 7) \Longrightarrow 1) $] Sea $x_0 \in X$, luego por hip\'otesis si $\norm{x - x_0}_X = 1$ entonces $\norm{T(x - x_0)}_Y \leq C$; por lo tanto:
		
		\begin{equation*}
		\begin{array}{cc}
			& \norm{T \left(\dfrac{x- x_0}{\norm{x - x_0}_X}\right)}_Y \leq C \\
			\Longrightarrow & \norm{T(x) - T(x_0)}_Y \leq C\norm{x- x_0}_X
		\end{array}
		\end{equation*}
		
		Cuando $\norm{x - x_0}_X < \delta = \frac{\epsilon}{C}$.
		\qed
	\end{enumerate}
\end{proof}

\begin{example}
	Si $X = Y = C[a,b]$ dotados de la norma supremo entonces $T(f)(x) = \int_{a}^{x}{f(t)dt}$ es un operador lineal acotado que no es un isomorfismo topol\'ogico.
\end{example}

\begin{corollary}
	Sean $X,Y$ normados y sea $T:X \rightarrow Y$ un isomorfismo lineal. Entonces $T$ es isomorfismo topol\'ogico si y s\'olo si existen $C_1,C_2 > 0$ tal que $C_1 \norm{x} \underbrace{\leq}_{\star} \norm{T(x)} \underbrace{\leq}_{\ast} C_2\norm{x}$
\end{corollary}

\begin{proof}
	Si $T$ es isomorfimso topol\'ogico entonces:
	
	\begin{equation*}
	\begin{array}{ccc}
	T \text{ continua } & \Longrightarrow & \exists C_2 > 0 \ / \ \norm{T(x)} \leq C_2 \norm{x} \quad \forall x \in X \\
	T^{-1} \text{ continua } & \Longrightarrow & \exists D_1 > 0 \ / \ \norm{T^{-1}(y)} \leq D_1 \norm{y} \quad \forall y \in Y \\
	 & \Longrightarrow & \norm{x} \leq D_1 \norm{T(x)} \quad \forall x \in X \\
	 & \Longrightarrow & C_1\norm{x} \leq \norm{T(x)} \quad \forall x \in X 
	\end{array}
	\end{equation*}
	
	Por lo tanto vale que:
	
	\[
		C_1 \norm{x} \leq \norm{T(x)} \leq C_2\norm{x}
	\]
	
	Rec\'iprocamente, por $\ast$ se concluye que $T$ es acotado y por \ref{Continuidad de un operador} es continua; asimismo de $\star$ si $x = T^{-1}(y)$ se ve que $T^{-1}$ es continua.
	
\end{proof}

\subsection{Espacios vectoriales de dimensi\'on finita}

\begin{definition}
	Si $\norm{.}_1, \norm{.}_2$ son dos normas en un espacio vectorial $X$ entonces decimos que son \textit{equivalentes} si $1_X : (X,\norm{.}_1) \rightarrow (X,\norm{.}_2)$ es un isomorfismo topol\'ogico.
\end{definition}

\begin{theorem}
	Sea $X$ un espacio vectorial de dimensi\'on finita, entonces:
	
	\begin{enumerate}
		\item Dos normas siempre son equivalentes
		\item $X$ es topol\'ogicamente isomorfo a $\R^n$ con $n = \dim X$
	\end{enumerate}
	
\end{theorem}

\begin{proof}
	\begin{enumerate}
		\item Sea $\norm{.}$ una norma en $X$ y veamos que $\norm{.}$ y $\norm{.}_{\infty}$ son equivalentes.
		
		Sea $a = \sum\limits_{i=1}^{k}{a_i e_i}$, luego $\norm{a} \leq \sum\limits_{i=1}^{k}{\abs{a_i}\norm{e_i}} \leq \norm{a}_{\infty}C$.
		
		Luego sea $id: (X,\norm{.}_{\infty}) \rightarrow (X,\norm{.})$
		
		Sabemos que $B_{1}[0]$ es compacta en $(X,\norm{.}_{\infty})$ y por la cuenta anterior $id$ es continua, por lo tanto $id(S) = S$ es compacta en $(X,\norm{.})$ y por ende alcanza m\'inimo y m\'aximo. 
		
		Sean $C_1 = \min\limits_{\norm{x}_{\infty} = 1} \norm{x}$ y $C_2 = \max\limits_{\norm{x}_{\infty} = 1} \norm{x}$, por lo tanto si $x \in X$ entonces:
		
		\[
		C_1 \leq \norm{\dfrac{x}{\norm{x}_{\infty}}} \leq C_2
		\]
		
		\item Si $x = \sum\limits_{i=1}^{k}{a_i e_i}$ definimos $T(x) = (a_1 , \dots, a_n)$, luego:
		
		$$C_1 \norm{x} \leq \norm{T(x)}_{\infty} = \norm{x}_{\infty} \leq C_2 \norm{x}$$
		
		Por lo que $T$ es isomorfismo topol\'ogico. \qed
	\end{enumerate}
\end{proof}

\begin{corollary}
	Todo espacio vectorial de dimensi\'on finita es Banach.
\end{corollary}

\begin{corollary}
	Si $X$ es normado de dimensi\'on finita, entonces todo subconjunto cerrado y acotado es compacto.
\end{corollary}

\begin{proof}
	Si $A\subseteq X$ es cerrado y acotado, entonces existe $x_0 \in X, r > 0$ tal que $A \subset B_{r}[x_0]$ y $B_{r}[x_0]$ es compacto pues $B_1[0]$ lo es. Por lo tanto $A$ es un cerrado en un compacto. \qed
\end{proof}

\begin{theorem}
	Si $X$ es un espacio normado de dimensi\'on infinita, entonces $B_1[0]$ no es compacta
\end{theorem}

\begin{proof}
	Veamos primero el siguiente lema:
	
	\begin{lemma}[Lema de Riesz]
		\label{Lema de Riesz}
		Sea $M \subseteq X$ un subespacio no denso en un Banach, dado $r \in (0,1)$ existe $x \in X$ tal que $\norm{x} = 1$ pero $d(x,M) \geq r$ 
	\end{lemma}
	
	\begin{proof}[Demostraci\'on del lema]
		Sea $y \in X \setminus \overline{M}$ y notemos$R = d(y,M)$, luego si $\epsilon > 0$ existe $m_1 \in M$ tal que $\norm{m_1 - y} < R + \epsilon$. Sea $x = \dfrac{y - m_1}{\norm{y - m_1}}$, luego $\norm{x}=1$ y:
		
		\[
		\begin{aligned}
		d(x,M) = & \inf\limits_{m \in M} \norm{x - m} \\ 
		= & \inf\limits_{m \in M} \norm{m - \dfrac{y}{\norm{y - m_1}} + \dfrac{m_1}{\norm{y - m_1}}} \\
		= & \dfrac{\inf\limits_{m \in M} \norm{m - y} }{\norm{m_1 - y}} \\
		= & \dfrac{R}{R + \epsilon} \nearrow 1
		\end{aligned}
		\]
		\qed
		
	\end{proof}
	
	Sea $x_1 \in \partial B_1[0]$, luego por \ref{Lema de Riesz} aplicado a $S_1 = \ip{x_1}$ existe $x_2 \in \partial B_1[0]$ tal que $\norm{x_1 - x_2} > \frac{1}{2}$.
	
	Inductivamente sea $x_n \in \partial B_1[0]$ tal que $d(x_n, S_{n-1}) = d(x_n , \sett{x_1 , x_2 , \dots , x_{n-1}}) > \frac{1}{2}$. Luego por construcci\'on $\sett{x_n}_{n \in \N} \subset B_1[0]$ es una sucesi\'on tal que $\norm{x_n - x_m} > \frac{1}{2}$ para todos $n \neq m$ por lo tanto es una sucesi\'on acotada que no admite subsucesi\'on convergente. Conclu\'imos que $B_1[0]$ no es compacto \qed
	
\end{proof}

\subsection{Espacio de Operadores entre espacios normados}

\begin{definition}
	Dados $X,Y$ normados decimos que $T : X \rightarrow Y$ es \textit{acotado} si vale \ref{eq: Operador acotado}. De \ref{Continuidad de un operador} vemos que un funcional es acotado si y s\'olo si es continuo.
	
	En ese caso definimos:
	
	\begin{equation*}
	\norm{T} = \sup \sett{\norm{T(x)}: \ \norm{x} \leq 1}
	\end{equation*}
	
\end{definition}

\begin{proposition}
	Si $T$ es un operador acotado entonces:
	\begin{equation}
	\label{eq: Normas equivalentes de un operador}
	\begin{aligned}
	\norm{T} := & \sup \sett{\norm{T(x)}: \ \norm{x} \leq 1} \\
	= & \sup \sett{\norm{T(x)}: \ \norm{x} = 1}\\
	= & \sup \sett{\dfrac{\norm{T(x)}}{\norm{x}}: \ x \neq 0}  \\
	= & \inf \sett{c > 0: \ \norm{T(x)} \leq c \norm{x} \ x \in X} 
	\end{aligned}	
	\end{equation}
	
	Es m\'as, vale que $\norm{T(x)} \leq \norm{T} \norm{x}$ para todo $x \in X$.
	
\end{proposition}

\begin{proof}
	Notemos(solo por esta demostraci\'on):
	
	\[
	\begin{array}{ccc}
	\norm{T}_2 & = & \sup \sett{\abs{T(x)}: \ \norm{x} = 1} \\
	\norm{T}_3 & = & \sup \sett{\dfrac{\abs{T(x)}}{\norm{x}}: \ x \neq 0} \\
	\norm{T}_4 & =  & \inf \sett{c > 0: \ \abs{T(x)} \leq c \norm{x} \ x \in X}
	\end{array}
	\]
	
	Vamos por partes, 
	
	\begin{itemize}
		\item Primero como $\sett{\abs{T(x)}: \ \norm{x} = 1} \subseteq \sett{\abs{T(x)}: \ \norm{x} \leq 1}$ entonces vale que $\norm{T}_2 \leq \norm{T}$. 
		
		Rec\'iprocamente, si $\norm{x} \leq 1$ entonces:
		
		\begin{equation*}
		\begin{array}{cc}
		& \abs{T\left(\dfrac{x}{\norm{x}}\right)} \leq \norm{T}_2 \\
		\Longrightarrow &	\dfrac{1}{\norm{x}}\abs{T(x)} \leq \norm{T}_2 \\
		\Longrightarrow &	\abs{T(x)} \leq \norm{T}_2 \norm{x} \leq \norm{T}_2 \\
		\Longrightarrow &	\sup\limits_{\norm{x} \leq 1} \abs{T(x)} \leq \norm{T}_2 \\
		\Longrightarrow &	\norm{T} \leq \norm{T}_2
		\end{array}
		\end{equation*}
		
		\item Si $x \neq 0$ entonces:
		
		\begin{equation*}
		\begin{array}{cc}
		& \abs{T\left(\dfrac{x}{\norm{x}}\right)}  \leq \norm{T}_2 \\
		\Longrightarrow &	\dfrac{1}{\norm{x}}\abs{T(x)} \leq \norm{T}_2 \\
		\Longrightarrow &	\sup\limits_{x \neq 0} \sett{\dfrac{1}{\norm{x}}\abs{T(x)}} \leq \norm{T}_2 \\
		\Longrightarrow &	\norm{T}_3 \leq \norm{T}_2
		\end{array}
		\end{equation*}
		
		Rec\'iprocamente notemos que $\sett{\abs{T(x)}: \ \norm{x} = 1} = \sett{\dfrac{\abs{T(x)}}{\norm{x}}: \ \norm{x} = 1} \subseteq \sett{\dfrac{\abs{T(x)}}{\norm{x}}: \ x \neq 0}$ por lo tanto $\norm{T}_2 \leq \norm{T}_3$.
		
		\item Sea $\epsilon > 0$, luego:
		
		\begin{equation*}
		\begin{array}{cc}
		& \abs{T\left(\dfrac{x}{\norm{x} + \epsilon}\right)} \leq \norm{T} \\
		\Longrightarrow  & \abs{T(x)} \leq \left(\norm{x} + \epsilon\right) \norm{T} \\
		\text{Si } \epsilon \rightarrow 0 \longrightarrow  & \abs{T(x)} \leq \norm{T} \norm{x} \\
		\longrightarrow  & \norm{T}_4 \leq \norm{T}
		\end{array}
		\end{equation*}
		
		Rec\'iprocamente, si $\norm{T(x)} \leq c \norm{x}$ entonces $\norm{T} \leq c$ por lo que $\norm{T} \leq \norm{T}_4$. \qed
		
	\end{itemize}
\end{proof}

\begin{definition}
	Sean $X,Y$ normados, definimos $L(X,Y) = \sett{T:X \rightarrow Y  \ / \ T \text{lineal y acotado}}$
\end{definition}

\begin{proposition}
	Si $X,Y$ son normados entonces $L(X,Y)$ es normado
\end{proposition}

\begin{proof}
	Probemos al desigualdad triangular pues las dem\'as son triviales:
	
	Sean $T,W : X \rightarrow Y$ lineales y acotadas, entonces $\norm{T + W} = \sup\limits_{\norm{x} \leq 1}{\norm{(T + W)(x)}} = \sup\limits_{\norm{x} \leq 1}{\norm{Tx + Wx}} \leq \sup\limits_{\norm{x} \leq 1}{\norm{Tx} + \norm{Wx}} \leq \sup\limits_{\norm{x} \leq 1}{\norm{T(x)}} + \sup\limits_{\norm{x} \leq 1}{\norm{W(x)}} = \norm{T} + \norm{W}$. \qed
	
\end{proof}

\begin{theorem}
	\label{Espacio de operadores es banach si lo es el codominio}
	Sean $X,Y$ normados, entonces $Y$ es de Banach si y s\'olo si $L(X,Y)$ es de Banach
\end{theorem}

\begin{proof}
	Sea $(T_n)_{n \in \N} \subset L(X,Y)$ una sucesi\'on de Cauchy, y sea $\epsilon > 0$ entonces existe $N \in \N$ tal que $\norm{T_n - T_m} < \epsilon$ para todos $n,m \geq N$.
	
	En particular dado $x \in B_{1}[0]$ vale que ${\norm{T_n(x) - T_m(x)}} \leq  \sup\limits_{\norm{x} \leq 1} {\norm{T_n(x) - T_m(x)}} = \norm{T_n - T_m} < \epsilon$ por lo que $\left(T_n(x)\right)_{n \in \N} \subset Y$ es una sucesi\'on de Cauchy; como $Y$ es Banach $\lim T_n(x) \in Y$. Adem\'as si $\norm{x} \geq 1$ entonces $\lim T_n(x) = \lim \norm{x}T_n\left(\dfrac{x}{\norm{x}}\right) = \norm{x} \lim T_n \left(\dfrac{x}{\norm{x}}\right) \in Y$; luego definimos:
	
	\[
	T(x) = \lim T_n(x) \quad \forall x \in X
	\]
	
	Veamos que $T_n \rightarrow T$ y que $T \in L(X,Y)$.
	
	\begin{itemize}
		
		\item Por \ref{La norma es continua} y la linealidad de $T_n$ vale que $T$ es lineal
		\item Sea $x \in B_1[0]$ y $\epsilon > 0$, luego sea $N \in \N$ tal que $\norm{T_n - T_m} < \epsilon$ para todos $n,m \geq N$; entonces $\norm{T(x)} = \norm{T(x) - T_N(x) + T_N(x)} \leq \norm{T(x) - T_N(x)} + \norm{T_N(x)} < \epsilon + C$.
		
		\item Sea $\epsilon > 0$, luego $\epsilon > \sup\limits_{\norm{x} \leq 1} {\norm{T_n(x) - T_m(x)}} \underrightarrow{m \rightarrow \infty} \sup\limits_{\norm{x} \leq 1} {\norm{T_n(x) - T(x)}} = \norm{T_n - T}$. 
	\end{itemize}
	
	La vuelta la probaremos con Hanh-Banach. \qed
	
\end{proof}

\begin{definition}
	Sea $X$ espacio normado, luego notamos $X^{\star} := L(X, \mathbb{F})$ y se llama \textit{espacio dual topol\'ogico}.
	
	Si pensamos a $X$ como espacio vectorial solamente tambi\'en esta definido $X^{'} := \sett{T:X \rightarrow \mathbb{F}, \ / \ T \text{ lineal}}$ el \textit{ dual algebraico}.

\end{definition}

\subsection{Espacios cocientes}

Sea $X$ un espacio vectorial normado y $S \subseteq X$ un subespacio cerrado. Definimos la siguiente relaci\'on de equivalencia en $X$:

\[
x \sim_S y \Longleftrightarrow \ x-y \in S
\]

y definimos $\norm{[x]}_S := \inf \sett{\norm{t} \ : \ x \in [t]}$.


\begin{proposition}
	El espacio $\left(\quotient{X}{S}, \norm{.}_S \right)$ es un espacio normado con la suma definida por $[x] + [y] = [x+y], [\lambda x] = \lambda.[x]$
\end{proposition}

\begin{proof}
	\begin{itemize}
		\item Sean $x,x' \in X$ tal que $[x] = [x']$, entonces $x - x' \in S$ por lo que $\lambda(x-x') \in S$; en conclusi\'on $\lambda . [x] := [\lambda x] = [\lambda x'] =: \lambda . [x']$.
		\item Sean $x,x'y,y' \in X$ tal que $[x] = [x']$, $[y] = [y']$, luego $x-x' \in S$ y $y-y' \in S$ por lo que $(x-x') + (y-y') = (x+y) - (x'+y') \in S$; en conclusi\'on $[x] + [y] := [x+y] = [x' + y'] =: [x'] + [y']$.
		\item Sean $[x] \in \quotient{X}{S}$, $\lambda \in \mathbb{F}$, luego $\norm{\lambda [x]} = \norm{[\lambda x]} = \inf\limits_{t \in [\lambda x]}{\norm{t}} = \inf\limits_{t \in [x]}{\norm{\lambda t}} = \abs{\lambda} \norm{[x]}$
		\item Sean $[x],[y] \in \quotient{X}{S}$, luego $\norm{[x] + [y]} = \norm{[x+y]} = \inf\limits_{t \in [x + y]}{\norm{t}} \leq \inf\limits_{t \in [x] \\ w \in [y]}{\norm{t+w}} \leq \norm{[x]} + \norm{[y]}$
		\item Si $\norm{[x]} = 0$ entonces existe $t_n$ tal que $\norm{t_n} < \frac{1}{n}$ con $t_n \in [x]$, por lo tanto $x + s_n = t_n \rightarrow 0$ y entonces $s_n \rightarrow -x$. Como $S$ es cerrado $-x \in S$ y como es subespacio $x \in S$; luego $[x]=[0]$
		
		Trivialmente si $x \in S$ entonces $[x] = [0]$ y entonces $\norm{[x]} = 0$. \qed
		
	\end{itemize}
\end{proof}

\begin{proposition}
	Sean $S \subseteq X$ un subespacio cerrado en un normado, entonces:
	
	\[
		\norm{[x]} = d(x,S)
	\]
	
\end{proposition}

\begin{proof}
	$d(x,S) = \inf\limits_{s \in S}{\norm{x - s}_X} = \inf\limits_{-s \in S}{\norm{x + s}_X} = \inf\limits_{t \in [x]}{\norm{t}_X}$.\qed
\end{proof}

\begin{theorem}
	\label{Propiedades del espacio cociente}
	Sea $M \subseteq X$ un subespacio cerrado de un espacio normado y notemos $Q: X \rightarrow \quotient{X}{M}$ la proyecci\'on can\'onica, entonces:
	
	\begin{enumerate}
		\item $Q$ es continua y $\norm{Q} \leq 1$.
		\item Si $X$ es de Banach entonces $\quotient{X}{M}$ lo es.
		\item Si $W \subset \quotient{X}{M}$ entonces $W$ es abierto si y s\'olo si $Q^{-1}(W)$ es abierto.
		\item Si $U \subset X$ es abierto entonces $Q(U) \subset \quotient{X}{M}$ es abierto.
	\end{enumerate}
	
\end{theorem}

\begin{proof}
	Vayamos de a partes:
	
	\begin{enumerate}
		\item $\norm{Q(x)} = \norm{[x]} = d(x,M) \leq \norm{x}$ pues $0 \in M$; conclu\'imos por \ref{Continuidad de un operador}.
		
		\item Sea $\left([x_n]\right) \subset \quotient{X}{M}$ una sucesi\'on tal que $\Bigsum{n \in \N}{\norm{[x_n]}} < \infty$, y para cada $n \in \N$ tal que $\norm{[x_n]} \neq 0$ sea $\epsilon_n = \norm{[x_n]}$. Luego $\norm{[x_n]} + \epsilon_n = 2\norm{[x_n]} >  \norm{x_n + m_n}$ para cierto $m_n \in M$  (Si $\norm{[x_n]} = 0$ entonces $x_n \in M$ y tomamos $m_n = -x_n \in M$), como $\Bigsum{n \in \N}{\norm{[x_n]}} < \infty$ entonces $\Bigsum{n \in \N}{\norm{m_n + x_n}} < \infty$ y por \ref{Banach si y solo si abs convergente es convergente} $\Bigsum{n \in \N}{m_n + x_n} \in X$. Como $S_p = \sum\limits_{n = 1}^{p}{x_n + m_n} \rightarrow \Bigsum{n \in \N}{m_n + x_n}:= v \in X$ y $Q$ es continua entonces $\sum\limits_{n = 1}^{p}{[x_n]} = Q\left(S_p\right) \rightarrow Q(v) \in \quotient{X}{M}$; conclu\'imos por \ref{Banach si y solo si abs convergente es convergente} que $\quotient{X}{M}$ es de Banach.
		
		\item Sea $W \subset \quotient{X}{M}$ tal que $Q^{-1}(W)$ es abierto, luego si $[x_0] \in W$ entonces $x_0 \in Q^{-1}(W)$ y existe un $r > 0$ tal que $x_0 + B_r(0) \subset Q^{-1}(W)$. Veamos el siguiente lema:
		
		\begin{lemma}
			$Q(B_r(0)) = B_r([0])$
		\end{lemma}
		
		\begin{proof}[Demostraci\'on del lema]
			Si $\norm{x} < r$, entonces $\norm{[x]} = \norm{Qx} \leq \norm{x} < r$. Rec\'iprocamente si $\norm{[x]} < r$ entonces existe $y \in M$ tal que $\norm{x+y} < r$ por lo que $[x] = Q(x+y) \in Q(B_r(0))$. \qed
		\end{proof}
		
		Por el lema $W = QQ^{-1}(W) \supset Q(x_0 + B_r(0)) = B_r([x_0])$ por lo que $W$ es abierto.
		
		\item Si $U \subset X$ es abierto entonces $Q^{-1}(Q(U)) = U + M = \Bigcup{m \in M}{U+y}$ que es una uni\'on de abiertos, por lo que $Q^{-1}(Q(U))$ es abierto; por el punto anterior $Q(U)$ es abierto. \qed
		
	\end{enumerate}
\end{proof}

\begin{proposition}
	Si $X$ es normado, $M \subseteq X$ es un subespacio cerrado y $N \subseteq X$ es de dimensi\'on finita entonces $M+N$ es un subespacio cerrado.
\end{proposition}

\begin{proof}
	Consideremos $Q: X \rightarrow \quotient{X}{M}$, como $\dim Q(N) \leq \dim N < \infty $ entonces $Q(N)$ es cerrado y como $Q$ es continua entonces $Q^{-1}(Q(N)) = N+M$ es cerrado .\qed
\end{proof}

\section{Teorema de Hahn-Banach}

\end{document}